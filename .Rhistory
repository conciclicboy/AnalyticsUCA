<<<<<<< HEAD
=======
if (!suppressWarnings(require(git2r))) {
install.packages("git2r", repos="http://cran.r-project.org/", quiet=TRUE)
library(git2r)
}
if (!suppressWarnings(require(git2r))) {
install.packages("git2r", repos="http://cran.r-project.org/", quiet=TRUE)
library(git2r)
}
if (!suppressWarnings(require(git2r))) {
install.packages("git2r", repos="http://cran.r-project.org/", quiet=TRUE)
library(git2r)
}
repo <- repository(".")
if (!("upstream" %in% remotes(repo))) {
remote_add(repo, "upstream", "https://github.com/conciclicboy/UCAanalytics")
}
conf <- config(repo)
if (is.null(conf$local$user.name) && is.null(conf$global$user.name)) {
message("Su usuario de Github username aún no ha sifo configurado para este repositorio.")
config(repo, user.name=readline("Github username: "))
}
if (is.null(conf$local$user.email) && is.null(conf$global$user.email)) {
message("Su email de Github aún no ha sifo configurado para este repositorio.")
config(repo, user.email=readline("Github email: "))
}
fetch(repo, "upstream")
checkout(repo, "master")
merge(repo, "upstream/master")
message("
Su copia local de UCAanalytics está ahora en sync con el master project.
Usted puede actualizar su copia remota haciendo click en 'Push' en el panel de 'Git' panel o
ejecutando:
push(repo, credentials=cred_user_pass(readline('Github username: '), readline('Github password: ')))
")
# Sync a forked copy of INSEADAnalytics with the master project.
if (!suppressWarnings(require(git2r))) {
install.packages("git2r", repos="http://cran.r-project.org/", quiet=TRUE)
library(git2r)
}
repo <- repository(".")
if (!("upstream" %in% remotes(repo))) {
remote_add(repo, "upstream", "https://github.com/conciclicboy/UCAanalytics")
}
conf <- config(repo)
if (is.null(conf$local$user.name) && is.null(conf$global$user.name)) {
message("Su usuario de Github username aún no ha sifo configurado para este repositorio.")
config(repo, user.name=readline("Github username: "))
}
if (is.null(conf$local$user.email) && is.null(conf$global$user.email)) {
message("Su email de Github aún no ha sifo configurado para este repositorio.")
config(repo, user.email=readline("Github email: "))
}
fetch(repo, "upstream")
checkout(repo, "master")
merge(repo, "upstream/master")
message("
Su copia local de UCAanalytics está ahora en sync con el master project.
Usted puede actualizar su copia remota haciendo click en 'Push' en el panel de 'Git' panel o
ejecutando:
push(repo, credentials=cred_user_pass(readline('Github username: '), readline('Github password: ')))
")
# push(repo, credentials=cred_user_pass(readline("Github username: "), readline("Github password: ")))
knitr::opts_chunk$set(echo = TRUE)
b<-read.csv("./data/tomslee_airbnb_amsterdam_1476_2017-07-22.csv")
#Voy a hacer una copia como una matriz solo para imprimirl
#No es necesario hacer esto cuando se trabaja en R, esto solo es
#Porque tenemos un archivo markdown y los data frames se imprimen feo
a<-data.matrix(b)
knitr::kable({
#df <- t(head(round(a,2), 5))
df <- t(head(b, 2))
colnames(df) <- sprintf("%02d", 1:ncol(df))
df
})
summary(b)
#b$var1 <- NULL
#b$var2 <- NULL
#b$var3 <- NULL
#b$var4 <- NULL
b$country <- NULL
b$borough <- NULL
b$bathrooms <- NULL
b$minstay <- NULL
colnames(b)
library(ggplot2)
pl <- ggplot(b,aes(x=price))
pl+geom_histogram(fill='blue',alpha=0.5)+theme_minimal()
#filtrando data frame entre percentiles 1 y 99 de la variable precio
b<- b [(b$price>=quantile(b$price,0.01)) & (b$price <= quantile(b$price,0.99)),]
#Graficando nuevamente
>>>>>>> 31f871ca23935da9e22c5d2c45e6c39f794d5717
pl <- ggplot(b,aes(x=price))
pl+geom_histogram(fill='blue',alpha=0.5)+theme_minimal()
#fig.height=4.5,
#Para no hacernos la vida imposible podemos hacer muchos scatter plot
#utilizando la función visualize de la librería radiant.data
#library(ggplot2)
#library(lubridate)
library(radiant.data)
#fig.height=4.5,
#Para no hacernos la vida imposible podemos hacer muchos scatter plot
#utilizando la función visualize de la librería radiant.data
#library(ggplot2)
#library(lubridate)
library(radiant.data)
visualize(dataset=b,
xvar=c("reviews","overall_satisfaction","accommodates","bedrooms",
"latitude", "longitude"),
yvar="price",
type="scatter",
custom=FALSE
)
pl<-ggplot(data=b,aes(y=price,x=neighborhood))
pl+geom_boxplot(fill='blue',alpha=0.5)+theme_minimal()+theme(axis.text.x=element_text(angle=90, hjust=1))
# límite inferior de los vecindarios a considerar
# Podemos agarrar 1%-2%-3%-4%-5% de elementos
lim_inferior<-nrow(b)*0.04
#conteo_vec
pl<-ggplot(data=b,aes(x=neighborhood))
pl+geom_bar(fill='blue',alpha=0.5)+theme_minimal()+theme(axis.text.x=element_text(angle=90, hjust=1)) +geom_hline(yintercept = lim_inferior)
# Todo lo que debe hacer es cambiar el límite inferior basado en los resultados
# anteriores. En este caso le he puesto 200, usted puede cambiarlo, o no.
c<- b[b$neighborhood %in%  names(table(b$neighborhood))[table(b$neighborhood) >= 700],]
#Volvamos a graficar el diagrama de dispersión
pl<-ggplot(data=c,aes(y=price,x=neighborhood))
pl+geom_boxplot(fill='blue',alpha=0.5)+theme_minimal()+theme(axis.text.x=element_text(angle=90, hjust=1))
# Please ENTER the percentage of data used for estimation
porcion_train = 0.9
porcion_test = 0.1
# Librería dplyr
library(dplyr)
# Creando índice con función "mutate"" de dplyr
# Esto lo utilizaremos solo como referencia
b <- mutate(b,id = row_number())
# Creando datos de entrenamiento con función "sample_frac" de dplyr
# La función toma una muestra aleatoria de tamaño "porcion_train" de "b"
train_set <- sample_frac(b,porcion_train)
# Creando datos de evaluación con función "anti_join" de dplyr
# La función extraen los datos de "b" que no coinciden con "train_set"
# usando como referencia la columna "id"
test_set <- anti_join(b, train_set, by = 'id')
#,results='asis'
#Creando modelo
model_1<- lm(formula = scale(price) ~ room_type + neighborhood +
reviews +overall_satisfaction + accommodates +
bedrooms,data = train_set)
# Reportando modelo: usted solo necesita poner "summary(model)"
# Eso le entrega los resultados del modelo pero se imprime en formato feo
# Nosotros lo vamos a imprimir como una "xtable" en "knitr::kable"
library(xtable)
#knitr::kable(xtable(summary(model_1)))
summary(model_1)
#Creando modelo
model_2<- lm(formula = log(price) ~ room_type + neighborhood +
reviews +overall_satisfaction + log(accommodates) +
bedrooms,data = train_set)
# Reportando modelo
summary(model_2)
#Creando modelo
model_3<- lm(formula = log(price) ~ room_type + neighborhood +
reviews +overall_satisfaction + log(accommodates)*bedrooms
+bedrooms,
data = train_set)
# Reportando modelo
<<<<<<< HEAD
knitr::kable(xtable(summary(model_2)))
model_3 <- rpart(price ~ room_type + neighborhood +
reviews +overall_satisfaction + accommodates +
bedrooms,data = train_set, method="anova")
# Sacando predicciones
pred_train_3=predict(model_3,train_set)#entrenamiento
pred_test_3=predict(model_3,test_set)#evaluación
# Predicciones
pred_train_4<-predict(model_4,as.matrix(X_train))
pred_test_4<-predict(model_4,as.matrix(X_test))
mae1<-mae(test_set$price,pred_test_1)
mae2<-mae(test_set$price,pred_test_2)
mae3<-mae(test_set$price,pred_test_3)
mae4<-mae(test_set$price,pred_test_4)
mae1
mae2
mae3
mae4
mean(b$price)
sd(b$price)
mean(pred_train_1)
sd(pred_train_1)
sd(pred_train_3)
sd(pred_train_4)
mean(pred_train_2)
mean(pred_train_3)
mean(pred_train_43)
mean(pred_train_4)
mean(pred_train_1)
mean(pred_train_21)
mean(pred_train_1)
mean(pred_train_2)
mean(pred_train_3)
mean(pred_train_4)
# Primero vamos a añadir a X_train y X_test los resultados del modelo lineal
xx<-cbind(X_train, as.matrix(pred_train_1))
View(xx)
# Primero vamos a añadir a X_train y X_test los resultados del modelo lineal
X_train_2<-cbind(X_train, as.matrix(pred_train_1),as.matrix(pred_train_2))
X_test_2<-cbind(X_test, as.matrix(pred_test_1),as.matrix(pred_test_2))
# Modelo
model_5 <- xgboost(data = as.matrix(X_train_2), label = as.matrix(y_train), max.depth = 4,
eta = 0.3, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
# Predicciones
pred_train_5<-predict(model_5,as.matrix(X_train_2))
pred_test_5<-predict(model_5,as.matrix(X_test_2))
# Predicciones
pred_train_5<-predict(model_5,as.matrix(X_train_2))
pred_test_5<-predict(model_5,as.matrix(X_test_2))
# Modelo
model_5 <- xgboost(data = as.matrix(X_train_2), label = as.matrix(y_train), max.depth = 4,
eta = 0.3, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
# Predicciones
pred_train_5<-predict(model_5,as.matrix(X_train_2))
pred_test_5<-predict(model_5,as.matrix(X_test_2))
colnames(X_train_2)
colnames(X_test_2)
colnames(X_train)
names(X_train)
names(X_train)[32]
names(X_train_2)[32]
?as.array()
y_1<-as.matrix(pred_train_1)
View(y_1)
# Primero vamos a añadir a X_train y X_test los resultados del modelo lineal
y_1<- as.matrix(pred_train_1)
y_2<- as.matrix(pred_train_2)
X_train_2<-cbind(X_train,y_1,y_2)
y_1<- as.matrix(pred_test_1)
y_2<- as.matrix(pred_test_2)
X_test_2<-cbind(X_test, y_1,y_2)
# Modelo
model_5 <- xgboost(data = as.matrix(X_train_2), label = as.matrix(y_train), max.depth = 4,
eta = 0.3, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
# Predicciones
pred_train_5<-predict(model_5,as.matrix(X_train_2))
pred_test_5<-predict(model_5,as.matrix(X_test_2))
# Error Medio
mae5<-mae(test_set$price,pred_test_5)
mae5
mae1
mae2
# Modelo
model_5 <- xgboost(data = as.matrix(X_train_2), label = as.matrix(y_train), max.depth = 4,
eta = 0.5, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
# Modelo
model_5 <- xgboost(data = as.matrix(X_train_2), label = as.matrix(y_train), max.depth = 4,
eta = 0.5, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
# Predicciones
pred_train_5<-predict(model_5,as.matrix(X_train_2))
pred_test_5<-predict(model_5,as.matrix(X_test_2))
# Error Medio
mae5<-mae(test_set$price,pred_test_5)
mae5
# Modelo
model_5 <- xgboost(data = as.matrix(X_train_2), label = as.matrix(y_train), max.depth = 4,
eta = 0.75, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
# Modelo
model_5 <- xgboost(data = as.matrix(X_train_2), label = as.matrix(y_train), max.depth = 4,
eta = 0.75, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
# Predicciones
pred_train_5<-predict(model_5,as.matrix(X_train_2))
mae5
# Modelo
model_5 <- xgboost(data = as.matrix(X_train_2), label = as.matrix(y_train), max.depth = 4,
eta = 1.05, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
# Predicciones
pred_train_5<-predict(model_5,as.matrix(X_train_2))
pred_test_5<-predict(model_5,as.matrix(X_test_2))
# Error Medio
mae5<-mae(test_set$price,pred_test_5)
mae5
# Modelo
model_5 <- xgboost(data = as.matrix(X_train_2), label = as.matrix(y_train), max.depth = 4,
eta = 1, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
# Modelo
model_5 <- xgboost(data = as.matrix(X_train_2), label = as.matrix(y_train), max.depth = 4,
eta = 1, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
# Predicciones
pred_train_5<-predict(model_5,as.matrix(X_train_2))
pred_test_5<-predict(model_5,as.matrix(X_test_2))
pred_test_5<-predict(model_5,as.matrix(X_test_2))
# Error Medio
mae5<-mae(test_set$price,pred_test_5)
mae5
# Modelo
model_5 <- xgboost(data = as.matrix(X_train_2), label = as.matrix(y_train), max.depth = 4,
eta = 0.5, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
# Predicciones
pred_train_5<-predict(model_5,as.matrix(X_train_2))
pred_test_5<-predict(model_5,as.matrix(X_test_2))
# Error Medio
mae5<-mae(test_set$price,pred_test_5)
mae5
# Primero vamos a definir las matrices de entrenamiento y evaluación
X_train<- train_set[,c(colnames(vecindarios),colnames(tipos_cuarto),"reviews",
"overall_satisfaction", "accommodates","bedrooms",
"longitude", "latitude")]
X_test<- test_set[,c(colnames(vecindarios),colnames(tipos_cuarto),"reviews",
"overall_satisfaction", "accommodates","bedrooms",
"longitude", "latitude")]
# Luego definimos los vectores de la variable dependiente
y_train<- train_set$price
y_test<-test_set$price
# Modelo
model_4 <- xgboost(data = as.matrix(X_train), label = as.matrix(y_train), max.depth = 4,
eta = 0.3, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
# Modelo
model_4 <- xgboost(data = as.matrix(X_train), label = as.matrix(y_train), max.depth = 4,
eta = 0.3, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
# Predicciones
pred_train_4<-predict(model_4,as.matrix(X_train))
# Predicciones
pred_train_4<-predict(model_4,as.matrix(X_train))
pred_test_4<-predict(model_4,as.matrix(X_test))
### Modelo 4: XGBoost
```{r,message=FALSE, warning=FALSE,eval=FALSE}
library(xgboost)
# Primero vamos a definir las matrices de entrenamiento y evaluación
X_train<- train_set[,c(colnames(vecindarios),colnames(tipos_cuarto),"reviews",
"overall_satisfaction", "accommodates","bedrooms",
"longitude", "latitude")]
X_test<- test_set[,c(colnames(vecindarios),colnames(tipos_cuarto),"reviews",
"overall_satisfaction", "accommodates","bedrooms",
"longitude", "latitude")]
# Luego definimos los vectores de la variable dependiente
y_train<- train_set$price
y_test<-test_set$price
# Modelo
model_4 <- xgboost(data = as.matrix(X_train), label = as.matrix(y_train), max.depth = 4,
eta = 0.3, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
# Modelo
model_4 <- xgboost(data = as.matrix(X_train), label = as.matrix(y_train), max.depth = 4,
eta = 0.3, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
# Predicciones
pred_train_4<-predict(model_4,as.matrix(X_train))
print("Modelo 1:",mae1)
print("Modelo 1:" & mae1)
print((paste("Modelo 1:" & mae1))
print((paste("Modelo 1:" & mae1)))
print((paste("Modelo 1:", mae1)))
print((paste("Modelo 2:", mae2)))
mae5
mae5/sum(y_test)
y_test
mae5/mean(y_test)
mae1/mean(y_test)
mae2/mean(y_test)
mae3/mean(y_test)
mae4/mean(y_test)
knitr::opts_chunk$set(echo = TRUE)
#obteniendo directorio
getwd()
b<-read.csv("./data/autos_ventas.csv")
b<-read.csv("./data/autos_ventas.csv")
View(b)
b<-read.csv("./data/autos_ventas.csv",sep = ";")
View(b)
View(b)
df <- t(head(round(a,2), 3))
knitr::kable({
#df <- t(head(round(a,2), 3))
df <- t(head(b, 2))
colnames(df) <- sprintf("%02d", 1:ncol(df))
df
})
#df <- t(head(round(a,2), 5))
df <- t(head(b, 2))
#df <- t(head(round(a,2), 5))
df <- t(head(b, 5))
=======
summary(model_3)
knitr::opts_chunk$set(echo = TRUE)
b<-read.csv("./data/autos_ventas.csv",sep = ";")
knitr::kable({
#df <- t(head(round(a,2), 5))
df <- t(head(b, 5))
colnames(df) <- sprintf("%02d", 1:ncol(df))
df
})
View(b)
colnames(b)
colnames(b)[1}]
colnames(b)[1]
colnames(b)[2]
colnames(b)[3]
b<-read.csv("./data/autos_ventas.csv",sep = ";")
knitr::kable({
#df <- t(head(round(a,2), 5))
df <- t(head(b, 5))
colnames(df) <- sprintf("%02d", 1:ncol(df))
df
})
View(b)
colnames(b)[1]
names(b$ï..Date)
b$ï..Date
colnames(b)[1]<-"Date"
colnames(b)[1]
typeof(b$Date)
#Graficando
pl <- ggplot(b,aes(x=Date,y=price))
#filtrando data frame entre percentiles 1 y 99 de la variable precio
#b<- b [(b$price>=quantile(b$price,0.01)) & (b$price <= quantile(b$price,0.99)),]
library(ggplot2)
#Graficando
pl <- ggplot(b,aes(x=Date,y=price))
pl+ geom_line()
#Graficando
pl <- ggplot(b,aes(x=Date,y=Car))
pl+ geom_line()
pl <- ggplot(b,aes(x=Date,y=Car))
pl+ geom_line()
x$Date
b$Date
b$Car
as.Date(b$Date)
?as.Date
b$Date
as.Date(b$Date,"%d/%m/%y")
b$Date
as.Date(b$Date,"%d/%m/%y")
b$Date
as.Date(b$Date,"%d/%m/%y")
b$Date
as.Date(b$Date,"%d/%m/%Y")
#Transformando en fecha
b$Date<- as.Date(b$Date,"%d/%m/%Y")
#Graficando
pl <- ggplot(b,aes(x=Date,y=Car))
pl+ geom_line()
#Graficando
pl <- ggplot(b,aes(x=Date,y=Car))
pl+ geom_line()+theme_minimal()
pl+ geom_line(size=2+theme_minimal()
pl+ geom_line(size=2)+theme_minimal()
pl+ geom_line()+theme_minimal()
pl+ geom_line(size=2)+theme_minimal()
pl+ geom_line(size=1)+theme_minimal()
pl+ geom_line(color='r',size=1)+theme_minimal()
pl+ geom_line(color="#00AFBB",size=1)+theme_minimal()
#Graficando
pl <- ggplot(b,aes(x=Date,y=c(Car,Truck,Total)))
pl+ geom_line(size=1)+theme_minimal()
?ggplot
pl <- ggplot(b,aes(x=Date,Car,Truck,Total))
pl+ geom_line(aes(Car),size=1)+geom_line(aes(Truck),size=1)+theme_minimal()
aes(Car)
aes(Cars)
b$Car
b$Truck
#Graficando
pl <- ggplot(b,aes(Date))
pl+ geom_line(aes(Car))+geom_line(aes(Truck))
#Graficando
pl <- ggplot(b,aes(Date))
pl+ geom_line(aes(Car))+geom_line(aes(Truck))
#Graficando
pl <- ggplot(b,aes(x=Date))
pl+ geom_line(aes(y=Car))+geom_line(aes(y=Truck))
pl+ geom_line(aes(y=Car))+geom_line(aes(y=Truck))+theme_minimal()
pl+ geom_line(aes(y=Car),size=1)+geom_line(aes(y=Truck),size=1)+theme_minimal()
pl+ geom_line(aes(y=Car),size=1,color="blue")+geom_line(aes(y=Truck),size=1)+theme_minimal()
pl+ geom_line(aes(y=Car),size=1,color="blue")+geom_line(aes(y=Truck),size=1,color="darkred")+theme_minimal()
#Transformando en fecha
b$Date<- as.Date(b$Date,"%d/%m/%Y")
#Transformando en fecha
b$Date<- as.Date(b$Date,"%d/%m/%Y")
b$Date<- as.Date(b$Date,"%d/%m/%Y")
b$Date
knitr::opts_chunk$set(echo = TRUE)
as.Date(b$Date,"%d/%m/%Y")
b<-read.csv("./data/autos_ventas.csv",sep = ";")
>>>>>>> 31f871ca23935da9e22c5d2c45e6c39f794d5717
knitr::kable({
#df <- t(head(round(a,2), 5))
df <- t(head(b, 5))
colnames(df) <- sprintf("%02d", 1:ncol(df))
df
})
<<<<<<< HEAD
=======
#Transformando en fecha
b$Date<- as.Date(b$Date,"%d/%m/%Y")
b
# Renombrando columna Date
colnames(b)[1]
# Renombrando columna Date
colnames(b)[1]<-"Date"
# Transformando en fecha
b$Date<- as.Date(b$Date,"%d/%m/%Y")
install.packages("Metrics")
pl+ geom_line(aes(y=Car),size=0.5,color="blue")+geom_line(aes(y=Truck),size=0.5,color="darkred")+theme_minimal()
# Renombrando columna Date
colnames(b)[1]<-"Date"
# Transformando en fecha
b$Date<- as.Date(b$Date,"%d/%m/%Y")
#Graficando
pl <- ggplot(b,aes(x=Date))
library(ggplot2)
#Graficando
pl <- ggplot(b,aes(x=Date))
pl+ geom_line(aes(y=Car),size=0.5,color="blue")+geom_line(aes(y=Truck),size=0.5,color="darkred")+theme_minimal()
pl+ geom_line(aes(y=Car),size=0.7,color="blue")+geom_line(aes(y=Truck),size=0.7,color="darkred")+theme_minimal()
pl+ geom_line(aes(y=Car),size=0.7)+geom_line(aes(y=Truck),size=0.7)+theme_minimal()+scale_color_brewer(palette="Paired")
pl+ geom_line(aes(y=Car),size=0.7,color="blue")+geom_line(aes(y=Truck),size=0.7,color="darkred")#+theme_minimal()+scale_color_brewer(palette="Paired")
pl+ geom_line(aes(y=Car),size=0.7,color="blue")+geom_line(aes(y=Truck),size=0.7,color="darkred")+theme_minimal()#+scale_color_brewer(palette="Paired")
pl+ geom_line(aes(y=Car),color="blue")+geom_line(aes(y=Truck),color="darkred")+theme_minimal()#+scale_color_brewer(palette="Paired")
pl+ geom_line(aes(y=Car),color="blue")+geom_line(aes(y=Truck),color="darkred")+theme_minimal()#+scale_color_brewer(palette="Paired")
>>>>>>> 31f871ca23935da9e22c5d2c45e6c39f794d5717
