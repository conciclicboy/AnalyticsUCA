?rapply()
max(moras[,1:ncol(moras)-1])
?max
moras["def"]<-apply(moras[,1:ncol(moras)-1],1,max)
View(moras)
moras$def<-as.integer(moras$def>=4)
diferencias<-moras[moras$def!=moras$def_real]
moras$def != moras$def_real
diferencias<-moras[moras$def != moras$def_real]
diferencias<-moras[moras$def != moras$def_real,]
View(diferencias)
apply(diferencias,0,max)
apply(diferencias,1,max)
apply(diferencias,2,max)
apply(diferencias,2,>=4)
View(data_probe)
moras$fecha<-data_probe$FECHA_EMISION
View(moras)
#Dataframe de diferencias
diferencias<-moras[moras$def != moras$def_real,]
order(diferencias,method = c("FECHA_EMISION"))
?order
order_by(FECHA_EMISION,diferencias)
order_by("FECHA_EMISION",diferencias)
order_by(FECHA_EMISION,diferencias)
?order_by()
?order
as.date(diferencias$fecha)
date(diferencias$fecha)
?date()
diferencias<-diferencias[order(fecha),]
diferencias<-diferencias[order(diferencias$fecha),]
View(diferencias)
tmp<-diferencias[1:17,]
apply(tmp,1,max)
apply(tmp,2,max)
apply(tmp,2,max)>=4
tmp<-diferencias[17,32]
apply(tmp,2,max)>=4
tmp<-diferencias[17:32,]
apply(tmp,2,max)>=4
View(tmp)
tmp<-diferencias[17:31,]
apply(tmp,2,max)>=4
View(tmp)
tmp<-diferencias[32,46]
apply(tmp,2,max)>=4
tmp<-diferencias[32,46]
tmp<-diferencias[32:46,]
apply(tmp,2,max)>=4
tmp<-diferencias[106:123,]
apply(tmp,2,max)>=4
View(tmp)
View(diferencias)
tmp<-diferencias[123:133,]
View(tmp)
tmp<-diferencias[124:133,]
apply(tmp,2,max)>=4
tmp<-diferencias[134:149,]
apply(tmp,2,max)>=4
tmp<-diferencias[150:165,]
tmp<-diferencias[150:166,]
apply(tmp,2,max)>=4
diferencias<-diferencias[167:nrow(diferencias),]
View(diferencias)
tmp<-diferencias[1:25,]
tmp<-diferencias[1:24,]
apply(tmp,2,max)>=4
diferencias<-diferencias[25:nrow(diferencias),]
tmp<-diferencias[1:24,]
tmp<-diferencias[1:23,]
View(tmp)
apply(tmp,2,max)>=4
diferencias<-diferencias[24:nrow(diferencias),]
tmp<-diferencias[1:12,]
View(tmp)
apply(tmp,2,max)>=4
diferencias<-diferencias[13:nrow(diferencias),]
tmp<-diferencias[1:16,]
tmp<-diferencias[1:15,]
apply(tmp,2,max)>=4
diferencias<-diferencias[16:nrow(diferencias),]
tmp<-diferencias[1:15,]
View(tmp)
apply(tmp,2,max)>=4
diferencias<-diferencias[16:nrow(diferencias),]
View(diferencias)
tmp<-diferencias[1:23,]
View(tmp)
apply(tmp,2,max)>=4
diferencias<-diferencias[24:nrow(diferencias),]
View(diferencias)
tmp<-diferencias[1:11,]
apply(tmp,2,max)>=4
diferencias<-diferencias[12:nrow(diferencias),]
tmp<-diferencias[1:10,]
apply(tmp,2,max)>=4
diferencias<-diferencias[11:nrow(diferencias),]
tmp<-diferencias[1:16,]
tmp<-diferencias[1:15,]
apply(tmp,2,max)>=4
diferencias<-diferencias[16:nrow(diferencias),]
tmp<-diferencias[1:11,]
apply(tmp,2,max)>=4
diferencias<-diferencias[12:nrow(diferencias),]
tmp<-diferencias[1:15,]
apply(tmp,2,max)>=4
diferencias<-diferencias[16:nrow(diferencias),]
tmp<-diferencias[1:16,]
apply(tmp,2,max)>=4
diferencias<-diferencias[17:nrow(diferencias),]
tmp<-diferencias[1:19,]
tmp<-diferencias[1:18,]
apply(tmp,2,max)>=4
diferencias<-diferencias[19:nrow(diferencias),]
tmp<-diferencias[1:12,]
apply(tmp,2,max)>=4
diferencias<-diferencias[13:nrow(diferencias),]
tmp<-diferencias[1:18,]
tmp<-diferencias[1:8,]
tmp<-diferencias[1:7,]
apply(tmp,2,max)>=4
diferencias<-diferencias[8:nrow(diferencias),]
tmp<-diferencias[1:5,]
apply(tmp,2,max)>=4
diferencias<-diferencias[6:nrow(diferencias),]
tmp<-diferencias[1:11,]
apply(tmp,2,max)>=4
diferencias<-diferencias[12:nrow(diferencias),]
tmp<-diferencias
apply(tmp,2,max)>=4
load("C:/Users/mario_sanchez/Desktop/BACK UP MARIO/MODELOS/CREDISIMAN/BEHAVIOUR/ECR ban/ECR_BAN2.RData")
View(modelo_1)
modelo_1$formula
library(ROCR)
?ROCR
MODELO_1
modelo_1$formula
modelo_1$call
modelo_1$formula
data_probe$HIJOS
modelo_1$call
glm(formula = DEFAULT ~ (TIEMPO_TRABAJO > 6) + (SUM_COMPRAS_12M > 500) +
(CONTEO_MORA60_12M > 3) + (SCORE_ACTUAL > 750) + (SALDO_MORA_TOTAL_ACTUAL >  10) +
NUMERO_CREDITO_OTOR_30_ACTUAL + NUMERO_CREDITO_MORA90M_ACTUAL + NUMERO_TARJETA_CREDITO_ACTUAL +
(TOTAL_MONTO_TARJETA_CREDITO_ACTUAL > 1000) + (TOTAL_CUOTA_TARJETA_CREDITO_ACTUAL < 1000) +
(MIN_MONTO_TARJETA_CREDITO_ACTUAL >   600) + (PROP_USO_TARJETA_MAXLIM_ACTUAL) +
(PEOR_CATEGORIA_RIESGO_TAR_ACTUAL == "A") + (PEOR_CATEGORIA_RIESGO_TAR_ACTUAL == "E") +
(MEJOR_CATEGORIA_RIESGO_BAN_ACTUAL == "A1") + (MEJOR_CATEGORIA_RIESGO_BAN_ACTUAL == "C2"),
family = binomial, data = data_entre, method = glm.fit)
modelo_mario<-glm(formula = DEFAULT ~ (TIEMPO_TRABAJO > 6) + (SUM_COMPRAS_12M > 500) +
(CONTEO_MORA60_12M > 3) + (SCORE_ACTUAL > 750) + (SALDO_MORA_TOTAL_ACTUAL >  10) +
NUMERO_CREDITO_OTOR_30_ACTUAL + NUMERO_CREDITO_MORA90M_ACTUAL + NUMERO_TARJETA_CREDITO_ACTUAL +
(TOTAL_MONTO_TARJETA_CREDITO_ACTUAL > 1000) + (TOTAL_CUOTA_TARJETA_CREDITO_ACTUAL < 1000) +
(MIN_MONTO_TARJETA_CREDITO_ACTUAL >   600) + (PROP_USO_TARJETA_MAXLIM_ACTUAL) +
(PEOR_CATEGORIA_RIESGO_TAR_ACTUAL == "A") + (PEOR_CATEGORIA_RIESGO_TAR_ACTUAL == "E") +
(MEJOR_CATEGORIA_RIESGO_BAN_ACTUAL == "A1") + (MEJOR_CATEGORIA_RIESGO_BAN_ACTUAL == "C2"),
family = binomial, data = data_entre, method = glm.fit)
#Cambiando ubicación
getwd()
setwd("C:/Users/mario_sanchez/Desktop/BACK UP MARIO/MODELOS/CREDISIMAN/BEHAVIOUR/ECR ban")
#Leyendo datos
train_set<-read.csv("data_entre.csv")
test_set<-read.csv("data_probe.csv")
modelo_mario<-glm(formula = DEFAULT ~ (TIEMPO_TRABAJO > 6) + (SUM_COMPRAS_12M > 500) +
(CONTEO_MORA60_12M > 3) + (SCORE_ACTUAL > 750) + (SALDO_MORA_TOTAL_ACTUAL >  10) +
NUMERO_CREDITO_OTOR_30_ACTUAL + NUMERO_CREDITO_MORA90M_ACTUAL + NUMERO_TARJETA_CREDITO_ACTUAL +
(TOTAL_MONTO_TARJETA_CREDITO_ACTUAL > 1000) + (TOTAL_CUOTA_TARJETA_CREDITO_ACTUAL < 1000) +
(MIN_MONTO_TARJETA_CREDITO_ACTUAL >   600) + (PROP_USO_TARJETA_MAXLIM_ACTUAL) +
(PEOR_CATEGORIA_RIESGO_TAR_ACTUAL == "A") + (PEOR_CATEGORIA_RIESGO_TAR_ACTUAL == "E") +
(MEJOR_CATEGORIA_RIESGO_BAN_ACTUAL == "A1") + (MEJOR_CATEGORIA_RIESGO_BAN_ACTUAL == "C2"),
family = binomial, data = train_set, method = glm.fit)
View(modelo_mario)
load("C:/Users/mario_sanchez/Desktop/BACK UP MARIO/MODELOS/CREDISIMAN/BEHAVIOUR/ECR ban/ECR_BAN2.RData")
y_test_pred<-predict(modelo_1,data_probe)
y_test_pred<-as.matrix(predict(modelo_1,data_probe))
View(y_test_pred)
y_train_pred<--as.matrix(predict(modelo_1,data_entre))
y_test_pred<-as.matrix(predict(modelo_1,data_probe))
y_train_pred<-as.matrix(predict(modelo_1,data_entre))
y_test_pred<-as.matrix(predict(modelo_1,data_probe))
View(y_train_pred)
modelo_1$y
y_train_pred<-as.matrix(predict(modelo_1,data_entre, type="response"))
y_test_pred<-as.matrix(predict(modelo_1,data_probe,type="response"))
View(y_train_pred)
library(ROCR)
pred<-ROCR::prediction(y_test_pred,y_test)
perf<-ROCR::performance(pred,"tpr","fpr")
pred<-ROCR::prediction(y_test_pred,y_test)
y_train<-data_entre$DEFAULT
y_test<-data_probe$DEFAULT
y_train_pred<-as.matrix(predict(modelo_1,data_entre, type="response"))
y_test_pred<-as.matrix(predict(modelo_1,data_probe,type="response"))
library(ROCR)
pred<-ROCR::prediction(y_test_pred,y_test)
perf<-ROCR::performance(pred,"tpr","fpr")
plot(perf,colorize=TRUE)
perf
ROCR::::.__C__prediction
roc_auc_1 <- ROCR::performance(pred,measure = "auc")
roc_auc_1
pred<-ROCR::prediction(y_test_pred,y_test)
perf<-ROCR::performance(pred,"tpr","fpr")
roc_auc_1 <- ROCR::performance(pred,measure = "auc")
View(roc_auc_1)
roc_auc_1@y.values
print(roc_auc_1@y.values)
pred<-ROCR::prediction(y_test_pred,y_test)
perf<-ROCR::performance(pred,"tpr","fpr")
plot(perf,colorize=TRUE)
roc_auc_1 <- ROCR::performance(pred,measure = "auc")
print(roc_auc_1@y.values)
View(pred)
pred@predictions[[1]]
View(y_test_pred)
y_test
y_train
knitr::opts_chunk$set(echo = TRUE)
#obteniendo directorio
#getwd()
# "b es el nombre de la variable que contiene los datos
# usted puede asignar cualquier nombre disponible como "datos" o "datos_autos"
# yo le puse "b" por simplicidad
b<-read.csv("./data/autos_ventas.csv",sep = ";")
#Imprimiento las primeras 5 filas
knitr::kable({
#df <- t(head(round(a,2), 5))
df <- t(head(b, 5))
colnames(df) <- sprintf("%02d", 1:ncol(df))
df
})
library(ggplot2)
# Renombrando columna Date
colnames(b)[1]<-"Date"
# Transformando en fecha
b$Date<- as.Date(b$Date,"%d/%m/%Y")
#Graficando
pl <- ggplot(b,aes(x=Date))
pl+ geom_line(aes(y=Car),color="blue")+geom_line(aes(y=Truck),color="darkred")+theme_minimal()+theme(axis.text.x=element_text(angle=90, hjust=1))#+scale_color_brewer(palette="Paired")
# Dividiendo datos en conjunto de entrenamiento y validación
# Como nuestros datos ya están ordenados por fecha es fácil hacerlo:
# usted puede simplemente tomar las primeras 274 filas y las ultimas 11
# yo utilice el año para ilustrar como se haría si no estuviera ordenado
library(lubridate)
train_set<-b[year(b$Date)< 2017,]
test_set<-b[year(b$Date) >= 2017,]
library(xtable)
# Modelo
model_1<- lm(Car ~ Time + Year+ Q1+ Q2+ Q3+
Inventories+CPI_New_Cars+CPI_Used_Cars+Gas_Prices+
Cons_Conf_Autos+Miles_Driven+Bank_Auto_Interest_Rate+
US_Population_millions+Unemployment+Disposible_Income_Capita_Real+
Saving_Capital+ Household_Debt_Capital+US_House_Price_Inflation+
Consumer_Confidence+RealGDP+Fed_Funds_Rate+US_Urban_CPI_Change+
Nonfarm_Payrolls,
data=train_set)
# Imprimiendo resultado
knitr::kable(xtable(summary(model_1)))
library(Metrics)
# Sacando predicciones
pred_train_1<-predict(model_1,train_set)
pred_test_1<-predict(model_1,test_set)
#Mean Absolute Error
mae1<-mae(test_set$Car,pred_test_1)
mae_train1<-mae(train_set$Car,pred_train_1)
print(paste("Train Error: ",mae_train1))
print(paste("Test Error: ",mae1))
train_set<-b[year(b$Date)< 2017,]
test_set<-b[year(b$Date) >= 2017,]
# Modelo
model_1<- lm(Truck ~ Time + Year+ Q1+ Q2+ Q3+
Inventories+CPI_New_Cars+CPI_Used_Cars+Gas_Prices+
Cons_Conf_Autos+Miles_Driven+Bank_Auto_Interest_Rate+
US_Population_millions+Unemployment+Disposible_Income_Capita_Real+
Saving_Capital+ Household_Debt_Capital+US_House_Price_Inflation+
Consumer_Confidence+RealGDP+Fed_Funds_Rate+US_Urban_CPI_Change+
Nonfarm_Payrolls,
data=train_set)
# Sacando predicciones
pred_train_1<-predict(model_1,train_set)
pred_test_1<-predict(model_1,test_set)
#Mean Absolute Error
mae1<-mae(test_set$Truck,pred_test_1)
mae_train1<-mae(train_set$Truck,pred_train_1)
print(paste("Train Error: ",mae_train1))
print(paste("Test Error: ",mae1))
train_set<-b[(year(b$Date)>=2010)&(year(b$Date)< 2017),]
test_set<-b[year(b$Date) >= 2017,]
# Modelo
model_2<- lm(Truck ~ Time + Year+ Q1+ Q2+ Q3+
Inventories+CPI_New_Cars+CPI_Used_Cars+Gas_Prices+
Cons_Conf_Autos+Miles_Driven+Bank_Auto_Interest_Rate+
US_Population_millions+Unemployment+Disposible_Income_Capita_Real+
Saving_Capital+ Household_Debt_Capital+US_House_Price_Inflation+
Consumer_Confidence+RealGDP+Fed_Funds_Rate+US_Urban_CPI_Change+
Nonfarm_Payrolls,
data=train_set)
# Sacando predicciones
pred_train_2<-predict(model_2,train_set)
pred_test_2<-predict(model_2,test_set)
#Mean Absolute Error
mae2<-mae(test_set$Truck,pred_test_2)
mae_train2<-mae(train_set$Truck,pred_train_2)
print(paste("Train Error: ",mae_train2))
print(paste("Test Error: ",mae2))
#Modelo
model_3<- lm(Truck~Time+Year+Q1+Q2+Q3+CPI_New_Cars+
+Cons_Conf_Autos+Miles_Driven+US_Population_millions+
Unemployment+Disposible_Income_Capita_Real+
US_House_Price_Inflation+Consumer_Confidence+RealGDP+
Fed_Funds_Rate+Nonfarm_Payrolls, data = train_set)
#Predicciones
pred_train_3<-predict(model_3,train_set)
pred_test_3<-predict(model_3,test_set)
#Error Absoluto Medio
mae_train3<-mae(y_train,pred_train_3)
#Modelo
model_3<- lm(Truck~Time+Year+Q1+Q2+Q3+CPI_New_Cars+
+Cons_Conf_Autos+Miles_Driven+US_Population_millions+
Unemployment+Disposible_Income_Capita_Real+
US_House_Price_Inflation+Consumer_Confidence+RealGDP+
Fed_Funds_Rate+Nonfarm_Payrolls, data = train_set)
#Datos Reales
y_train<-train_set$Truck
y_test<- test_set$Truck
#Predicciones
pred_train_3<-predict(model_3,train_set)
pred_test_3<-predict(model_3,test_set)
#Error Absoluto Medio
mae_train3<-mae(y_train,pred_train_3)
mae3<-mae(y_test,pred_test_3)
#Reportando error
print(paste("train set: ",mae_train3))
print(paste("test set: ",mae3))
X_train<-train_set[,c("Time","Year", "Q1","Q2","Q3",
"CPI_New_Cars", "Cons_Conf_Autos","Miles_Driven",
"US_Population_millions","Unemployment",
"Disposible_Income_Capita_Real",
"US_House_Price_Inflation",
"Consumer_Confidence","RealGDP","Fed_Funds_Rate",
"Nonfarm_Payrolls")]
X_test<-test_set[,c("Time","Year", "Q1","Q2","Q3",
"CPI_New_Cars",
"Cons_Conf_Autos","Miles_Driven",
"US_Population_millions","Unemployment",
"Disposible_Income_Capita_Real",
"US_House_Price_Inflation",
"Consumer_Confidence","RealGDP","Fed_Funds_Rate",
"Nonfarm_Payrolls")]
y_train<-train_set$Truck
y_test<- test_set$Truck
model_3<-cv.glmnet(as.matrix(X_train),as.matrix(y_train),
family="gaussian", alpha = 1, nlambda=25)
X_train<-train_set[,c("Time","Year", "Q1","Q2","Q3",
"CPI_New_Cars", "Cons_Conf_Autos","Miles_Driven",
"US_Population_millions","Unemployment",
"Disposible_Income_Capita_Real",
"US_House_Price_Inflation",
"Consumer_Confidence","RealGDP","Fed_Funds_Rate",
"Nonfarm_Payrolls")]
X_test<-test_set[,c("Time","Year", "Q1","Q2","Q3",
"CPI_New_Cars",
"Cons_Conf_Autos","Miles_Driven",
"US_Population_millions","Unemployment",
"Disposible_Income_Capita_Real",
"US_House_Price_Inflation",
"Consumer_Confidence","RealGDP","Fed_Funds_Rate",
"Nonfarm_Payrolls")]
y_train<-train_set$Truck
y_test<- test_set$Truck
model_4<-cv.glmnet(as.matrix(X_train),as.matrix(y_train),
family="gaussian", alpha = 1, nlambda=25)
library(glmnet)
X_train<-train_set[,c("Time","Year", "Q1","Q2","Q3",
"CPI_New_Cars", "Cons_Conf_Autos","Miles_Driven",
"US_Population_millions","Unemployment",
"Disposible_Income_Capita_Real",
"US_House_Price_Inflation",
"Consumer_Confidence","RealGDP","Fed_Funds_Rate",
"Nonfarm_Payrolls")]
X_test<-test_set[,c("Time","Year", "Q1","Q2","Q3",
"CPI_New_Cars",
"Cons_Conf_Autos","Miles_Driven",
"US_Population_millions","Unemployment",
"Disposible_Income_Capita_Real",
"US_House_Price_Inflation",
"Consumer_Confidence","RealGDP","Fed_Funds_Rate",
"Nonfarm_Payrolls")]
y_train<-train_set$Truck
y_test<- test_set$Truck
model_4<-cv.glmnet(as.matrix(X_train),as.matrix(y_train),
family="gaussian", alpha = 1, nlambda=25)
# Sacando predicciones
pred_train_4=predict(model_4, newx = as.matrix(X_train), s = "lambda.min")
pred_test_4=predict(model_4, newx=as.matrix(X_test), s = "lambda.min")
#Mean Absolute Error
mae_train4<-mae(y_train,pred_train_4)
mae4<-mae(y_test,pred_test_4)
# reportando errores
print(paste("train set: ",mae_train4))
print(paste("test set: ",mae4))
1
make_pdf_file = 0 # DEJE ESTE NÚMERO COMO 0 SI QUIERE PRODUCIR UN ARCHIVO HTML, 1 PARA UN PDF
local_directory = "."
source(paste(local_directory,"../../AnalyticsLibraries/library.R", sep="/"))
source(paste(local_directory,"../../AnalyticsLibraries/heatmapOutput.R", sep = "/"))
# Package options
ggthemr('fresh')  # ggplot theme
opts_knit$set(progress=FALSE, verbose=FALSE)
opts_chunk$set(echo=FALSE, fig.align="center", fig.width=10, fig.height=6.2)
options(knitr.kable.NA = '')
dformat <-function(df) {
if (class(df) != "data.frame")
df <- as.data.frame(df)
x <- lapply(colnames(df), function(col) {
if (is.numeric(df[, col]))
normalize_bar(rgb(238, 238, 238, max=255), min=0.1, na.rm=TRUE)
else
formatter("span")
})
names(x) <- colnames(df)
formattable(df, x)
}
if (make_pdf_file) {
dformat<- function(df) knitr::kable(df)
}
# SET UP
# When running the case on a local computer, modify this in case you saved the case in a different directory
# (e.g. local_directory <- "C:/user/MyDocuments" )
# type in the Console below help(getwd) and help(setwd) for more information
#local_directory <- paste(getwd(),"CourseSessions/Sessions67", sep="/")
#local_directory <- "~INSEADAnalytics/CourseSessions/Sessions67"
# Please ENTER the filename that indicates subsets of the data to use (e.g. only a specific cluster)
# This file need to have 2 columns with the second one indicating the cluster ID of the observation.
# The rows of this files are aligned with those of the datafile_name one
# This is used ONLY for the report "MyBoatsDrivers"
cluster_file_ini = "Boats_cluster" # make sure this file exists in the "data" directory
datafile_name = "Boats"
# Please ENTER the class (dependent) variable:
# Please use numbers, not column names! e.g. 82 uses the 82nd column are dependent variable.
# YOU NEED TO MAKE SURE THAT THE DEPENDENT VARIABLES TAKES ONLY 2 VALUES: 0 and 1!!!
dependent_variable= 82
# Please ENTER the attributes to use as independent variables
# Please use numbers, not column names! e.g. c(1:5, 7, 8) uses columns 1,2,3,4,5,7,8
independent_variables= c(54:80) # use 54-80 for boats
# Please ENTER the profit/cost values for the correctly and wrong classified data:
actual_1_predict_1 = 100
actual_1_predict_0 = -75
actual_0_predict_1 = -50
actual_0_predict_0 = 0
# Please ENTER the probability threshold above which an observations
# is predicted as class 1:
Probability_Threshold=50 # between 1 and 99%
# Please ENTER the percentage of data used for estimation
estimation_data_percent = 80
validation_data_percent = 10
# Please enter 0 if you want to "randomly" split the data in estimation and validation/test
random_sampling = 0
# Tree parameter
# PLEASE ENTER THE Tree (CART) complexity control cp (e.g. 0.001 to 0.02, depending on the data)
CART_cp = 0.01
# Please enter the minimum size of a segment for the analysis to be done only for that segment
min_segment = 100
# Please enter the maximum number of observations to show in the report and slides
# (DEFAULT is 50. If the number is large the report and slides may not be generated - very slow or will crash!!)
max_data_report = 10 # can also chance in server.R
Probability_Threshold = Probability_Threshold/100 # make it between 0 and 1
ProjectData <- read.csv(paste(paste(local_directory, "data", sep="/"), paste(datafile_name,"csv", sep="."), sep = "/")) # this contains only the matrix ProjectData
ProjectData=data.matrix(ProjectData)
# if (datafile_name == "Boats")
#   colnames(ProjectData)<-gsub("\\."," ",colnames(ProjectData))
dependent_variable = unique(sapply(dependent_variable,function(i) min(ncol(ProjectData), max(i,1))))
independent_variables = unique(sapply(independent_variables,function(i) min(ncol(ProjectData), max(i,1))))
if (length(unique(ProjectData[,dependent_variable])) !=2){
cat("\n*****\n BE CAREFUL, THE DEPENDENT VARIABLE TAKES MORE THAN 2 VALUES...")
cat("\nSplitting it around its median...\n*****\n ")
new_dependent = ProjectData[,dependent_variable] >= median(ProjectData[,dependent_variable])
ProjectData[,dependent_variable] <- 1*new_dependent
}
Profit_Matrix = matrix(c(actual_1_predict_1, actual_0_predict_1, actual_1_predict_0, actual_0_predict_0), ncol=2)
colnames(Profit_Matrix)<- c("Predict 1", "Predict 0")
rownames(Profit_Matrix) <- c("Actual 1", "Actual 0")
test_data_percent = 100-estimation_data_percent-validation_data_percent
CART_control = rpart.control(cp = CART_cp)
source("../AnalyticsLibraries/library.R")
source("./AnalyticsLibraries/library.R")
make_pdf_file = 0 # Haga este número 1 si quiere un archivo PDF, 0 para HTML
source("../AnalyticsLibraries/library.R")
getwd()
source(".../AnalyticsLibraries/library.R")
source("../AnalyticsLibraries/library.R")
getwd()
source("./AnalyticsLibraries/library.R")
source("/AnalyticsLibraries/library.R")
source("AnalyticsLibraries/library.R")
getwd()
print(getwd())
source("../AnalyticsLibraries/library.R")
setwd("../")
print(getwd())
setwd("../")
print(getwd())
source("../../AnalyticsLibraries/library.R")
source("../../AnalyticsLibraries/heatmapOutput.R")
# Por favor INGRESE el nombre del archivo
datafile_name = "../../Data/UCI_Credit_Card.csv"
# Por favor INGRESE el nombre del archivo
datafile_name = "../../Data/UCI_Credit_Card.csv"
ProjectData <- read.csv(datafile_name)
# Convertimos los datos a la clase data.matrix para que sea mas fácil de manipular
ProjectData <- data.matrix(ProjectData)
