eval_metric="rmse")
# Modelo
model_4 <- xgboost(data = as.matrix(X_train), label = as.matrix(y_train), max.depth = 6,
eta = 1.2, nthread = 6, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
mae4<-mae(as.matrix(y_test),predict(model_4,as.matrix(X_test)))
mae4
# Modelo
model_4 <- xgboost(data = as.matrix(X_train), label = as.matrix(y_train), max.depth = 3,
eta = 1.2, nthread = 6, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
mae4<-mae(as.matrix(y_test),predict(model_4,as.matrix(X_test)))
mae4
# Modelo
model_4 <- xgboost(data = as.matrix(X_train), label = as.matrix(y_train), max.depth = 3,
eta = 1.2, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
mae4<-mae(as.matrix(y_test),predict(model_4,as.matrix(X_test)))
mae4
mae1
mae2
mae3
mae4
pred_1<-as.matrix(pred_1)
View(pred_1)
pred_2<-as.matrix(pred_2)
pred_3<-as.matrix(pred_3)
pred_4<-as.matrix(pred_4)
View(pred_1)
View(pred_2)
View(pred_3)
View(pred_4)
#Primero vamos a definir las matrices de entrenamiento y evaluación
X_train<- train_set[,c(colnames(vecindarios),colnames(tipos_cuarto),"reviews",
"overall_satisfaction", "accommodates","bedrooms")]
X_test<- test_set[,c(colnames(vecindarios),colnames(tipos_cuarto),"reviews",
"overall_satisfaction", "accommodates","bedrooms")]
#Luego definimos los vectores de la variable dependiente
y_train<- train_set$price
y_test<-test_set$price
#Primero vamos a definir las matrices de entrenamiento y evaluación
X_train<- train_set[,c(colnames(vecindarios),colnames(tipos_cuarto),"reviews",
"overall_satisfaction", "accommodates","bedrooms",
"longitude", "latitude")]
X_test<- test_set[,c(colnames(vecindarios),colnames(tipos_cuarto),"reviews",
"overall_satisfaction", "accommodates","bedrooms",
"longitude", "latitude")]
#Luego definimos los vectores de la variable dependiente
y_train<- train_set$price
y_test<-test_set$price
# Modelo
model_4 <- xgboost(data = as.matrix(X_train), label = as.matrix(y_train), max.depth = 3,
eta = 1.2, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
#Luego definimos los vectores de la variable dependiente
y_train<- train_set$price
y_test<-test_set$price
# Modelo
model_4 <- xgboost(data = as.matrix(X_train), label = as.matrix(y_train), max.depth = 3,
eta = 1.2, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
# Modelo
model_4 <- xgboost(data = as.matrix(X_train), label = as.matrix(y_train), max.depth = 3,
eta = 1, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
# Modelo
model_4 <- xgboost(data = as.matrix(X_train), label = as.matrix(y_train), max.depth = 3,
eta = 1, nthread = 2, nrounds = 300, objective = "reg:linear",
eval_metric="rmse")
mae4<-mae(as.matrix(y_test),predict(model_4,as.matrix(X_test)))
mae4
mae3
# Modelo
model_4 <- xgboost(data = as.matrix(X_train), label = as.matrix(y_train), max.depth = 3,
eta = 0.1, nthread = 2, nrounds = 300, objective = "reg:linear",
eval_metric="rmse")
mae4<-mae(as.matrix(y_test),predict(model_4,as.matrix(X_test)))
mae4
mae1
mae2
mae3
# Modelo
model_4 <- xgboost(data = as.matrix(X_train), label = as.matrix(y_train), max.depth = 3,
eta = 0.3, nthread = 2, nrounds = 300, objective = "reg:linear",
eval_metric="rmse")
mae4<-mae(as.matrix(y_test),predict(model_4,as.matrix(X_test)))
mae4
# Modelo
model_4 <- xgboost(data = as.matrix(X_train), label = as.matrix(y_train), max.depth = 3,
eta = 0.3, nthread = 2, nrounds = 1000, objective = "reg:linear",
eval_metric="rmse")
mae4<-mae(as.matrix(y_test),predict(model_4,as.matrix(X_test)))
mae4
# Modelo
model_4 <- xgboost(data = as.matrix(X_train), label = as.matrix(y_train), max.depth = 2,
eta = 0.3, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
# Modelo
model_4 <- xgboost(data = as.matrix(X_train), label = as.matrix(y_train), max.depth = 4,
eta = 0.3, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
mae4<-mae(as.matrix(y_test),predict(model_4,as.matrix(X_test)))
mae4
# Sacando predicciones
pred_train_1=predict(model_1,train_set)
pred_test_1=predict(model_1,test_set)
# Creando modelo
model_2<-lm(formula = log(price) ~ room_type + neighborhood +
reviews +overall_satisfaction + log(accommodates) +
bedrooms,data = train_set)
# Sacando predicciones
pred_train_2=exp(predict(model_2,train_set))
pred_test_2=exp(predict(model_2,test_set))
# Reportando modelo
knitr::kable(xtable(summary(model_2)))
model_3 <- rpart(price ~ room_type + neighborhood +
reviews +overall_satisfaction + accommodates +
bedrooms,data = train_set, method="anova")
# Sacando predicciones
pred_train_3=predict(model_3,train_set)#entrenamiento
pred_test_3=predict(model_3,test_set)#evaluación
# Predicciones
pred_train_4<-predict(model_4,as.matrix(X_train))
pred_test_4<-predict(model_4,as.matrix(X_test))
mae1<-mae(test_set$price,pred_test_1)
mae2<-mae(test_set$price,pred_test_2)
mae3<-mae(test_set$price,pred_test_3)
mae4<-mae(test_set$price,pred_test_4)
mae1
mae2
mae3
mae4
mean(b$price)
sd(b$price)
mean(pred_train_1)
sd(pred_train_1)
sd(pred_train_3)
sd(pred_train_4)
mean(pred_train_2)
mean(pred_train_3)
mean(pred_train_43)
mean(pred_train_4)
mean(pred_train_1)
mean(pred_train_21)
mean(pred_train_1)
mean(pred_train_2)
mean(pred_train_3)
mean(pred_train_4)
# Primero vamos a añadir a X_train y X_test los resultados del modelo lineal
xx<-cbind(X_train, as.matrix(pred_train_1))
View(xx)
# Primero vamos a añadir a X_train y X_test los resultados del modelo lineal
X_train_2<-cbind(X_train, as.matrix(pred_train_1),as.matrix(pred_train_2))
X_test_2<-cbind(X_test, as.matrix(pred_test_1),as.matrix(pred_test_2))
# Modelo
model_5 <- xgboost(data = as.matrix(X_train_2), label = as.matrix(y_train), max.depth = 4,
eta = 0.3, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
# Predicciones
pred_train_5<-predict(model_5,as.matrix(X_train_2))
pred_test_5<-predict(model_5,as.matrix(X_test_2))
# Predicciones
pred_train_5<-predict(model_5,as.matrix(X_train_2))
pred_test_5<-predict(model_5,as.matrix(X_test_2))
# Modelo
model_5 <- xgboost(data = as.matrix(X_train_2), label = as.matrix(y_train), max.depth = 4,
eta = 0.3, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
# Predicciones
pred_train_5<-predict(model_5,as.matrix(X_train_2))
pred_test_5<-predict(model_5,as.matrix(X_test_2))
colnames(X_train_2)
colnames(X_test_2)
colnames(X_train)
names(X_train)
names(X_train)[32]
names(X_train_2)[32]
?as.array()
y_1<-as.matrix(pred_train_1)
View(y_1)
# Primero vamos a añadir a X_train y X_test los resultados del modelo lineal
y_1<- as.matrix(pred_train_1)
y_2<- as.matrix(pred_train_2)
X_train_2<-cbind(X_train,y_1,y_2)
y_1<- as.matrix(pred_test_1)
y_2<- as.matrix(pred_test_2)
X_test_2<-cbind(X_test, y_1,y_2)
# Modelo
model_5 <- xgboost(data = as.matrix(X_train_2), label = as.matrix(y_train), max.depth = 4,
eta = 0.3, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
# Predicciones
pred_train_5<-predict(model_5,as.matrix(X_train_2))
pred_test_5<-predict(model_5,as.matrix(X_test_2))
# Error Medio
mae5<-mae(test_set$price,pred_test_5)
mae5
mae1
mae2
# Modelo
model_5 <- xgboost(data = as.matrix(X_train_2), label = as.matrix(y_train), max.depth = 4,
eta = 0.5, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
# Modelo
model_5 <- xgboost(data = as.matrix(X_train_2), label = as.matrix(y_train), max.depth = 4,
eta = 0.5, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
# Predicciones
pred_train_5<-predict(model_5,as.matrix(X_train_2))
pred_test_5<-predict(model_5,as.matrix(X_test_2))
# Error Medio
mae5<-mae(test_set$price,pred_test_5)
mae5
# Modelo
model_5 <- xgboost(data = as.matrix(X_train_2), label = as.matrix(y_train), max.depth = 4,
eta = 0.75, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
# Modelo
model_5 <- xgboost(data = as.matrix(X_train_2), label = as.matrix(y_train), max.depth = 4,
eta = 0.75, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
# Predicciones
pred_train_5<-predict(model_5,as.matrix(X_train_2))
mae5
# Modelo
model_5 <- xgboost(data = as.matrix(X_train_2), label = as.matrix(y_train), max.depth = 4,
eta = 1.05, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
# Predicciones
pred_train_5<-predict(model_5,as.matrix(X_train_2))
pred_test_5<-predict(model_5,as.matrix(X_test_2))
# Error Medio
mae5<-mae(test_set$price,pred_test_5)
mae5
# Modelo
model_5 <- xgboost(data = as.matrix(X_train_2), label = as.matrix(y_train), max.depth = 4,
eta = 1, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
# Modelo
model_5 <- xgboost(data = as.matrix(X_train_2), label = as.matrix(y_train), max.depth = 4,
eta = 1, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
# Predicciones
pred_train_5<-predict(model_5,as.matrix(X_train_2))
pred_test_5<-predict(model_5,as.matrix(X_test_2))
pred_test_5<-predict(model_5,as.matrix(X_test_2))
# Error Medio
mae5<-mae(test_set$price,pred_test_5)
mae5
# Modelo
model_5 <- xgboost(data = as.matrix(X_train_2), label = as.matrix(y_train), max.depth = 4,
eta = 0.5, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
# Predicciones
pred_train_5<-predict(model_5,as.matrix(X_train_2))
pred_test_5<-predict(model_5,as.matrix(X_test_2))
# Error Medio
mae5<-mae(test_set$price,pred_test_5)
mae5
# Primero vamos a definir las matrices de entrenamiento y evaluación
X_train<- train_set[,c(colnames(vecindarios),colnames(tipos_cuarto),"reviews",
"overall_satisfaction", "accommodates","bedrooms",
"longitude", "latitude")]
X_test<- test_set[,c(colnames(vecindarios),colnames(tipos_cuarto),"reviews",
"overall_satisfaction", "accommodates","bedrooms",
"longitude", "latitude")]
# Luego definimos los vectores de la variable dependiente
y_train<- train_set$price
y_test<-test_set$price
# Modelo
model_4 <- xgboost(data = as.matrix(X_train), label = as.matrix(y_train), max.depth = 4,
eta = 0.3, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
# Modelo
model_4 <- xgboost(data = as.matrix(X_train), label = as.matrix(y_train), max.depth = 4,
eta = 0.3, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
# Predicciones
pred_train_4<-predict(model_4,as.matrix(X_train))
# Predicciones
pred_train_4<-predict(model_4,as.matrix(X_train))
pred_test_4<-predict(model_4,as.matrix(X_test))
### Modelo 4: XGBoost
```{r,message=FALSE, warning=FALSE,eval=FALSE}
library(xgboost)
# Primero vamos a definir las matrices de entrenamiento y evaluación
X_train<- train_set[,c(colnames(vecindarios),colnames(tipos_cuarto),"reviews",
"overall_satisfaction", "accommodates","bedrooms",
"longitude", "latitude")]
X_test<- test_set[,c(colnames(vecindarios),colnames(tipos_cuarto),"reviews",
"overall_satisfaction", "accommodates","bedrooms",
"longitude", "latitude")]
# Luego definimos los vectores de la variable dependiente
y_train<- train_set$price
y_test<-test_set$price
# Modelo
model_4 <- xgboost(data = as.matrix(X_train), label = as.matrix(y_train), max.depth = 4,
eta = 0.3, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
# Modelo
model_4 <- xgboost(data = as.matrix(X_train), label = as.matrix(y_train), max.depth = 4,
eta = 0.3, nthread = 2, nrounds = 100, objective = "reg:linear",
eval_metric="rmse")
# Predicciones
pred_train_4<-predict(model_4,as.matrix(X_train))
print("Modelo 1:",mae1)
print("Modelo 1:" & mae1)
print((paste("Modelo 1:" & mae1))
print((paste("Modelo 1:" & mae1)))
print((paste("Modelo 1:", mae1)))
print((paste("Modelo 2:", mae2)))
mae5
mae5/sum(y_test)
y_test
mae5/mean(y_test)
mae1/mean(y_test)
mae2/mean(y_test)
mae3/mean(y_test)
mae4/mean(y_test)
knitr::opts_chunk$set(echo = TRUE)
#obteniendo directorio
getwd()
b<-read.csv("./data/autos_ventas.csv")
b<-read.csv("./data/autos_ventas.csv")
View(b)
b<-read.csv("./data/autos_ventas.csv",sep = ";")
View(b)
View(b)
df <- t(head(round(a,2), 3))
knitr::kable({
#df <- t(head(round(a,2), 3))
df <- t(head(b, 2))
colnames(df) <- sprintf("%02d", 1:ncol(df))
df
})
#df <- t(head(round(a,2), 5))
df <- t(head(b, 2))
#df <- t(head(round(a,2), 5))
df <- t(head(b, 5))
knitr::kable({
#df <- t(head(round(a,2), 5))
df <- t(head(b, 5))
colnames(df) <- sprintf("%02d", 1:ncol(df))
df
})
knitr::opts_chunk$set(echo = TRUE)
pl+ geom_line(aes(y=Car),color="blue")+geom_line(aes(y=Truck),color="darkred")+theme_minimal+theme(axis.text.x=element_text(angle=90, hjust=1))()#+scale_color_brewer(palette="Paired")
pl+ geom_line(aes(y=Car),color="blue")+geom_line(aes(y=Truck),color="darkred")+theme_minimal()+theme(axis.text.x=element_text(angle=90, hjust=1))#+scale_color_brewer(palette="Paired")
colnames(b)[6:ncol(b)]
knitr::opts_chunk$set(echo = TRUE)
#obteniendo directorio
#getwd()
b<-read.csv("./data/autos_ventas.csv",sep = ";")
#Imprimiento las primeras 5 filas
knitr::kable({
#df <- t(head(round(a,2), 5))
df <- t(head(b, 5))
colnames(df) <- sprintf("%02d", 1:ncol(df))
df
})
library(ggplot2)
# Renombrando columna Date
colnames(b)[1]<-"Date"
# Transformando en fecha
b$Date<- as.Date(b$Date,"%d/%m/%Y")
#Graficando
pl <- ggplot(b,aes(x=Date))
pl+ geom_line(aes(y=Car),color="blue")+geom_line(aes(y=Truck),color="darkred")+theme_minimal()+theme(axis.text.x=element_text(angle=90, hjust=1))#+scale_color_brewer(palette="Paired")
colnames(b)
colnames(b)[10:ncol(b)]
b<-read.csv("./data/autos_ventas.csv",sep = ";",fileEncoding = "UTF-8")
View(b)
b<-read.csv("./data/autos_ventas.csv",sep = ";",fileEncoding = "UTF-8")
b<-read.csv("./data/autos_ventas.csv",sep = ";")
b<-read.csv("./data/autos_ventas.csv",sep = ";", header = TRUE)
View(b)
b<-read.csv("./data/autos_ventas.csv",sep = ";", encoding = "UTF-8")
View(b)
b<-read.csv("./data/autos_ventas.csv",sep = ";")
b<-read.csv("./data/autos_ventas.csv",sep = ";",check.names=FALSE)
View(b)
colnames(b)
library(radiant.data)
library(radiant.data)
visualize(dataset=b,
xvar=c("Inventories (000s)", "CPI New Cars NSA YoY", "CPI Used Cars NSA YoY"),
yvar="price",
type="scatter",
custom=FALSE
)
library(radiant.data)
visualize(dataset=b,
xvar=c("Inventories (000s)", "CPI New Cars NSA YoY", "CPI Used Cars NSA YoY"),
yvar="Cars",
type="scatter",
custom=FALSE
)
visualize(dataset=b,
xvar=c("Inventories (000s)", "CPI New Cars NSA YoY", "CPI Used Cars NSA YoY"),
yvar="Car",
type="scatter",
custom=FALSE
)
visualize(dataset=b,
xvar="Inventories (000s)",
yvar="price",
type="scatter",
custom=FALSE
)
visualize(dataset=b,
xvar="Inventories (000s)",
yvar="car",
type="scatter",
custom=FALSE
)
visualize(dataset=b,
xvar="Inventories (000s)",
yvar="Car",
type="scatter",
custom=FALSE
)
b<-read.csv("./data/autos_ventas.csv",sep = ";")
knitr::kable({
#df <- t(head(round(a,2), 5))
df <- t(head(b, 5))
colnames(df) <- sprintf("%02d", 1:ncol(df))
df
})
visualize(dataset=b,
xvar=c("Inventories..000s.","CPI.New.Cars.NSA.YoY","CPI.Used.Cars.NSA.YoY","Gas.Prices"),
yvar="Car",
type="scatter",
custom=FALSE
)
library(radiant.data)
visualize(dataset=b,
xvar=c("Inventories..000s.","CPI.New.Cars.NSA.YoY","CPI.Used.Cars.NSA.YoY",
"Gas.Prices", "Cons..Conf..Autos", "Miles.Driven", "Bank.Auto.Interest.Rate",
"US.Population..in.mill..", "Unempl..Rate", "Disposible.Income.Capita.Real",
"Saving...Capita", "Household.Debt...Capita", "US.House.Price.Inflation.NSA",
"Consumer.Confidence", "Annualized.RealGDP...Capita", "Fed.Funds.Rate",
"US.Urban.CPI.Change.NSA", "Nonfarm.Mfg.Payrolls.NSA"),
yvar="Car",
type="scatter",
custom=FALSE
)
#
#
#
#
#
visualize(dataset=b,
xvar=c("Inventories..000s.","CPI.New.Cars.NSA.YoY","CPI.Used.Cars.NSA.YoY",
"Gas.Prices", "Cons..Conf..Autos", "Miles.Driven"),
yvar="Car",
type="scatter",
custom=FALSE
)
library(radiant.data)
visualize(dataset=b,
xvar=c("Inventories..000s.","CPI.New.Cars.NSA.YoY","CPI.Used.Cars.NSA.YoY",
"Gas.Prices", "Cons..Conf..Autos", "Miles.Driven"),
yvar="Car",
type="scatter",
custom=FALSE
)
visualize(dataset=b,
xvar=c("Bank.Auto.Interest.Rate","US.Population..in.mill..", "Unempl..Rate",
"Disposible.Income.Capita.Real","Saving...Capita", "Household.Debt...Capita"),
yvar="Car",
type="scatter",
custom=FALSE
)
visualize(dataset=b,
xvar=c("US.House.Price.Inflation.NSA","Consumer.Confidence","Annualized.RealGDP...Capita",
"Fed.Funds.Rate","US.Urban.CPI.Change.NSA", "Nonfarm.Mfg.Payrolls.NSA"),
yvar="Car",
type="scatter",
custom=FALSE
)
colnames(b)
b<-read.csv("./data/autos_ventas.csv",sep = ";")
colnames(b)
knitr::opts_chunk$set(echo = TRUE)
model_3 <- rpart(price ~ room_type + neighborhood +
reviews +overall_satisfaction + accommodates +
bedrooms,data = train_set, method="anova")
#Graficando
pl <- ggplot(b,aes(x=Date))
pl+ geom_histogram(aes(y=Car),color="blue")+geom_histogram(aes(y=Truck),color="darkred")+theme_minimal()+theme(axis.text.x=element_text(angle=90, hjust=1))#+scale_color_brewer(palette="Paired")
geom_histogram(aes(y=Car),color="blue")+geom_histogram(aes(y=Truck),color="darkred")+theme_minimal()+theme(axis.text.x=element_text(angle=90, hjust=1))#+scale_color_brewer(palette="Paired")
gggplot(b,aes(x=Car))+geom_histogram()
ggplot(b,aes(x=Car))+geom_histogram()
ggplot(b,aes(x=Car))+geom_histogram(bins=10)
ggplot(b,aes(x=Car))+geom_histogram(bins=20)
ggplot(b,aes(x=Car))+geom_histogram(bins=20)+theme_minimal()
ggplot(b,aes(x=Car))+geom_histogram(bins=20,color="blue")+theme_minimal()
#Graficando
pl<-ggplot(b,aes(x=Car))
pl+geom_histogram(bins=20,color="blue")+theme_minimal()
#+geom_histogram(aes(y=Truck),color="darkred")+theme_minimal()+theme(axis.text.x=element_text(angle=90, hjust=1))#+scale_color_brewer(palette="Paired")
#geom_histogram()
pl+geom_histogram(bins=20,fill='blue',alpha=0.4)+theme_minimal()
pl+geom_histogram(bins=20,fill='blue',alpha=0.4,color="blue")+theme_minimal()
#Graficando Camiones
pl<-ggplot(b,aes(x=Truck))
#Graficando Carros
pl<-ggplot(b,aes(x=Car))
pl+geom_histogram(bins=20,fill='blue',alpha=0.4,color="blue")+theme_minimal()
#Graficando Camiones
pl<-ggplot(b,aes(x=Truck))
pl+geom_histogram(bins=20,fill='blue',alpha=0.4,color="blue")+theme_minimal()
