model_4<-cv.glmnet(as.matrix(X_train),as.matrix(y_train),
family="gaussian", nlambda=100,dfmax=20)
#model_4<- lm(y_train~as.matrix(X_train))
# Sacando predicciones
pred_train_4=predict(model_4, newx = as.matrix(X_train), s = "lambda.min")
pred_test_4=predict(model_4, newx = as.matrix(X_test), s = "lambda.min")
#Mean Absolute Error
mae_train4<-mae(y_train,pred_train_4)
mae4<-mae(y_test,pred_test_4)
# reportando errores
print(paste("train set: ",mae_train4))
print(paste("test set: ",mae4))
train_set<-b[(year(b$Date)>=2010)&(year(b$Date)< 2017),]
test_set<-b[year(b$Date) >= 2017,]
# Modelo
model_2<- lm(Truck ~ Time + Year+ Q1+ Q2+ Q3+
Inventories+CPI_New_Cars+CPI_Used_Cars+Gas_Prices+
Cons_Conf_Autos+Miles_Driven+Bank_Auto_Interest_Rate+
US_Population_millions+Unemployment+Disposible_Income_Capita_Real+
Saving_Capital+ Household_Debt_Capital+US_House_Price_Inflation+
Consumer_Confidence+RealGDP+Fed_Funds_Rate+US_Urban_CPI_Change+
Nonfarm_Payrolls,
data=train_set)
# Sacando predicciones
pred_train_2<-predict(model_2,train_set)
pred_test_2<-predict(model_2,test_set)
#Mean Absolute Error
mae2<-mae(test_set$Truck,pred_test_2)
mae_train2<-mae(train_set$Truck,pred_train_2)
print(paste("Train Error: ",mae_train2))
print(paste("Test Error: ",mae2))
load("C:/Users/mario_sanchez/Desktop/BACK UP MARIO/MODELOS/CREDISIMAN/.RData")
getwd()
knitr::opts_chunk$set(echo = TRUE)
#obteniendo directorio
#getwd()
# "b es el nombre de la variable que contiene los datos
# usted puede asignar cualquier nombre disponible como "datos" o "datos_autos"
# yo le puse "b" por simplicidad
b<-read.csv("./data/autos_ventas.csv",sep = ";")
#Imprimiento las primeras 5 filas
knitr::kable({
#df <- t(head(round(a,2), 5))
df <- t(head(b, 5))
colnames(df) <- sprintf("%02d", 1:ncol(df))
df
})
library(ggplot2)
# Renombrando columna Date
colnames(b)[1]<-"Date"
# Transformando en fecha
b$Date<- as.Date(b$Date,"%d/%m/%Y")
#Graficando
pl <- ggplot(b,aes(x=Date))
pl+ geom_line(aes(y=Car),color="blue")+geom_line(aes(y=Truck),color="darkred")+theme_minimal()+theme(axis.text.x=element_text(angle=90, hjust=1))#+scale_color_brewer(palette="Paired")
# Haremos esto en porciones porque el programa va tronar si hacemos todos los
library(radiant.data)
visualize(dataset=b,
xvar=c("Inventories", "CPI_New_Cars", "CPI_Used_Cars",
"Gas_Prices", "Cons_Conf_Autos", "Miles_Driven"),
yvar="Car",
type="scatter",
custom=FALSE
)
visualize(dataset=b,
xvar=c("Bank_Auto_Interest_Rate", "US_Population_millions", "Unemployment",
"Disposible_Income_Capita_Real", "Saving_Capital", "Household_Debt_Capital"),
yvar="Car",
type="scatter",
custom=FALSE
)
visualize(dataset=b,
xvar=c("US_House_Price_Inflation", "Consumer_Confidence", "RealGDP",
"Fed_Funds_Rate", "US_Urban_CPI_Change", "Nonfarm_Payrolls"),
yvar="Car",
type="scatter",
custom=FALSE
)
# Dividiendo datos en conjunto de entrenamiento y validación
# Como nuestros datos ya están ordenados por fecha es fácil hacerlo:
# usted puede simplemente tomar las primeras 274 filas y las ultimas 11
# yo utilice el año para ilustrar como se haría si no estuviera ordenado
library(lubridate)
train_set<-b[year(b$Date)< 2017,]
test_set<-b[year(b$Date) >= 2017,]
load("C:/Users/mario_sanchez/Desktop/BACK UP MARIO/MODELOS/CREDISIMAN/BEHAVIOUR/ECR ban/ECR_BAN2.RData")
a<-colnames(data_entre)
a<-data.frame(colnames(data_entre))
View(a)
head(data_probe$MEJOR_CATEGORIA_RIESGO_TAR_ACTUAL)
head(data_probe$MEJOR_CATEGORIA_RIESGO_TAR_ACTUAL,10)
head(data_probe$MEJOR_CATEGORIA_RIESGO_TAR_ACTUAL,20)
getwd()
getwd()
setwd("C:/Users/mario_sanchez/Desktop/BACK UP MARIO/MODELOS/CREDISIMAN/BEHAVIOUR/ECR ban")
train_set<-read.csv("data_entre.csv")
test_set<-read.csv("data_probe.csv")
View(a)
#Averiguando cual es el default correcto
moras<- test_set[,58:112]
View(moras)
moras["def_real"]<-test_set$DEFAULT
View(moras)
moras["def"]<-apply(moras[,1:ncol(moras)-1],max)
max(moras[,1:ncol(moras)-1])
apply(array, margin, ...)
?apply(
)
?rapply(list, function)
?rapply()
max(moras[,1:ncol(moras)-1])
?max
moras["def"]<-apply(moras[,1:ncol(moras)-1],1,max)
View(moras)
moras$def<-as.integer(moras$def>=4)
diferencias<-moras[moras$def!=moras$def_real]
moras$def != moras$def_real
diferencias<-moras[moras$def != moras$def_real]
diferencias<-moras[moras$def != moras$def_real,]
View(diferencias)
apply(diferencias,0,max)
apply(diferencias,1,max)
apply(diferencias,2,max)
apply(diferencias,2,>=4)
View(data_probe)
moras$fecha<-data_probe$FECHA_EMISION
View(moras)
#Dataframe de diferencias
diferencias<-moras[moras$def != moras$def_real,]
order(diferencias,method = c("FECHA_EMISION"))
?order
order_by(FECHA_EMISION,diferencias)
order_by("FECHA_EMISION",diferencias)
order_by(FECHA_EMISION,diferencias)
?order_by()
?order
as.date(diferencias$fecha)
date(diferencias$fecha)
?date()
diferencias<-diferencias[order(fecha),]
diferencias<-diferencias[order(diferencias$fecha),]
View(diferencias)
tmp<-diferencias[1:17,]
apply(tmp,1,max)
apply(tmp,2,max)
apply(tmp,2,max)>=4
tmp<-diferencias[17,32]
apply(tmp,2,max)>=4
tmp<-diferencias[17:32,]
apply(tmp,2,max)>=4
View(tmp)
tmp<-diferencias[17:31,]
apply(tmp,2,max)>=4
View(tmp)
tmp<-diferencias[32,46]
apply(tmp,2,max)>=4
tmp<-diferencias[32,46]
tmp<-diferencias[32:46,]
apply(tmp,2,max)>=4
tmp<-diferencias[106:123,]
apply(tmp,2,max)>=4
View(tmp)
View(diferencias)
tmp<-diferencias[123:133,]
View(tmp)
tmp<-diferencias[124:133,]
apply(tmp,2,max)>=4
tmp<-diferencias[134:149,]
apply(tmp,2,max)>=4
tmp<-diferencias[150:165,]
tmp<-diferencias[150:166,]
apply(tmp,2,max)>=4
diferencias<-diferencias[167:nrow(diferencias),]
View(diferencias)
tmp<-diferencias[1:25,]
tmp<-diferencias[1:24,]
apply(tmp,2,max)>=4
diferencias<-diferencias[25:nrow(diferencias),]
tmp<-diferencias[1:24,]
tmp<-diferencias[1:23,]
View(tmp)
apply(tmp,2,max)>=4
diferencias<-diferencias[24:nrow(diferencias),]
tmp<-diferencias[1:12,]
View(tmp)
apply(tmp,2,max)>=4
diferencias<-diferencias[13:nrow(diferencias),]
tmp<-diferencias[1:16,]
tmp<-diferencias[1:15,]
apply(tmp,2,max)>=4
diferencias<-diferencias[16:nrow(diferencias),]
tmp<-diferencias[1:15,]
View(tmp)
apply(tmp,2,max)>=4
diferencias<-diferencias[16:nrow(diferencias),]
View(diferencias)
tmp<-diferencias[1:23,]
View(tmp)
apply(tmp,2,max)>=4
diferencias<-diferencias[24:nrow(diferencias),]
View(diferencias)
tmp<-diferencias[1:11,]
apply(tmp,2,max)>=4
diferencias<-diferencias[12:nrow(diferencias),]
tmp<-diferencias[1:10,]
apply(tmp,2,max)>=4
diferencias<-diferencias[11:nrow(diferencias),]
tmp<-diferencias[1:16,]
tmp<-diferencias[1:15,]
apply(tmp,2,max)>=4
diferencias<-diferencias[16:nrow(diferencias),]
tmp<-diferencias[1:11,]
apply(tmp,2,max)>=4
diferencias<-diferencias[12:nrow(diferencias),]
tmp<-diferencias[1:15,]
apply(tmp,2,max)>=4
diferencias<-diferencias[16:nrow(diferencias),]
tmp<-diferencias[1:16,]
apply(tmp,2,max)>=4
diferencias<-diferencias[17:nrow(diferencias),]
tmp<-diferencias[1:19,]
tmp<-diferencias[1:18,]
apply(tmp,2,max)>=4
diferencias<-diferencias[19:nrow(diferencias),]
tmp<-diferencias[1:12,]
apply(tmp,2,max)>=4
diferencias<-diferencias[13:nrow(diferencias),]
tmp<-diferencias[1:18,]
tmp<-diferencias[1:8,]
tmp<-diferencias[1:7,]
apply(tmp,2,max)>=4
diferencias<-diferencias[8:nrow(diferencias),]
tmp<-diferencias[1:5,]
apply(tmp,2,max)>=4
diferencias<-diferencias[6:nrow(diferencias),]
tmp<-diferencias[1:11,]
apply(tmp,2,max)>=4
diferencias<-diferencias[12:nrow(diferencias),]
tmp<-diferencias
apply(tmp,2,max)>=4
load("C:/Users/mario_sanchez/Desktop/BACK UP MARIO/MODELOS/CREDISIMAN/BEHAVIOUR/ECR ban/ECR_BAN2.RData")
View(modelo_1)
modelo_1$formula
library(ROCR)
?ROCR
MODELO_1
modelo_1$formula
modelo_1$call
modelo_1$formula
data_probe$HIJOS
modelo_1$call
glm(formula = DEFAULT ~ (TIEMPO_TRABAJO > 6) + (SUM_COMPRAS_12M > 500) +
(CONTEO_MORA60_12M > 3) + (SCORE_ACTUAL > 750) + (SALDO_MORA_TOTAL_ACTUAL >  10) +
NUMERO_CREDITO_OTOR_30_ACTUAL + NUMERO_CREDITO_MORA90M_ACTUAL + NUMERO_TARJETA_CREDITO_ACTUAL +
(TOTAL_MONTO_TARJETA_CREDITO_ACTUAL > 1000) + (TOTAL_CUOTA_TARJETA_CREDITO_ACTUAL < 1000) +
(MIN_MONTO_TARJETA_CREDITO_ACTUAL >   600) + (PROP_USO_TARJETA_MAXLIM_ACTUAL) +
(PEOR_CATEGORIA_RIESGO_TAR_ACTUAL == "A") + (PEOR_CATEGORIA_RIESGO_TAR_ACTUAL == "E") +
(MEJOR_CATEGORIA_RIESGO_BAN_ACTUAL == "A1") + (MEJOR_CATEGORIA_RIESGO_BAN_ACTUAL == "C2"),
family = binomial, data = data_entre, method = glm.fit)
modelo_mario<-glm(formula = DEFAULT ~ (TIEMPO_TRABAJO > 6) + (SUM_COMPRAS_12M > 500) +
(CONTEO_MORA60_12M > 3) + (SCORE_ACTUAL > 750) + (SALDO_MORA_TOTAL_ACTUAL >  10) +
NUMERO_CREDITO_OTOR_30_ACTUAL + NUMERO_CREDITO_MORA90M_ACTUAL + NUMERO_TARJETA_CREDITO_ACTUAL +
(TOTAL_MONTO_TARJETA_CREDITO_ACTUAL > 1000) + (TOTAL_CUOTA_TARJETA_CREDITO_ACTUAL < 1000) +
(MIN_MONTO_TARJETA_CREDITO_ACTUAL >   600) + (PROP_USO_TARJETA_MAXLIM_ACTUAL) +
(PEOR_CATEGORIA_RIESGO_TAR_ACTUAL == "A") + (PEOR_CATEGORIA_RIESGO_TAR_ACTUAL == "E") +
(MEJOR_CATEGORIA_RIESGO_BAN_ACTUAL == "A1") + (MEJOR_CATEGORIA_RIESGO_BAN_ACTUAL == "C2"),
family = binomial, data = data_entre, method = glm.fit)
#Cambiando ubicación
getwd()
setwd("C:/Users/mario_sanchez/Desktop/BACK UP MARIO/MODELOS/CREDISIMAN/BEHAVIOUR/ECR ban")
#Leyendo datos
train_set<-read.csv("data_entre.csv")
test_set<-read.csv("data_probe.csv")
modelo_mario<-glm(formula = DEFAULT ~ (TIEMPO_TRABAJO > 6) + (SUM_COMPRAS_12M > 500) +
(CONTEO_MORA60_12M > 3) + (SCORE_ACTUAL > 750) + (SALDO_MORA_TOTAL_ACTUAL >  10) +
NUMERO_CREDITO_OTOR_30_ACTUAL + NUMERO_CREDITO_MORA90M_ACTUAL + NUMERO_TARJETA_CREDITO_ACTUAL +
(TOTAL_MONTO_TARJETA_CREDITO_ACTUAL > 1000) + (TOTAL_CUOTA_TARJETA_CREDITO_ACTUAL < 1000) +
(MIN_MONTO_TARJETA_CREDITO_ACTUAL >   600) + (PROP_USO_TARJETA_MAXLIM_ACTUAL) +
(PEOR_CATEGORIA_RIESGO_TAR_ACTUAL == "A") + (PEOR_CATEGORIA_RIESGO_TAR_ACTUAL == "E") +
(MEJOR_CATEGORIA_RIESGO_BAN_ACTUAL == "A1") + (MEJOR_CATEGORIA_RIESGO_BAN_ACTUAL == "C2"),
family = binomial, data = train_set, method = glm.fit)
View(modelo_mario)
load("C:/Users/mario_sanchez/Desktop/BACK UP MARIO/MODELOS/CREDISIMAN/BEHAVIOUR/ECR ban/ECR_BAN2.RData")
y_test_pred<-predict(modelo_1,data_probe)
y_test_pred<-as.matrix(predict(modelo_1,data_probe))
View(y_test_pred)
y_train_pred<--as.matrix(predict(modelo_1,data_entre))
y_test_pred<-as.matrix(predict(modelo_1,data_probe))
y_train_pred<-as.matrix(predict(modelo_1,data_entre))
y_test_pred<-as.matrix(predict(modelo_1,data_probe))
View(y_train_pred)
modelo_1$y
y_train_pred<-as.matrix(predict(modelo_1,data_entre, type="response"))
y_test_pred<-as.matrix(predict(modelo_1,data_probe,type="response"))
View(y_train_pred)
library(ROCR)
pred<-ROCR::prediction(y_test_pred,y_test)
perf<-ROCR::performance(pred,"tpr","fpr")
pred<-ROCR::prediction(y_test_pred,y_test)
y_train<-data_entre$DEFAULT
y_test<-data_probe$DEFAULT
y_train_pred<-as.matrix(predict(modelo_1,data_entre, type="response"))
y_test_pred<-as.matrix(predict(modelo_1,data_probe,type="response"))
library(ROCR)
pred<-ROCR::prediction(y_test_pred,y_test)
perf<-ROCR::performance(pred,"tpr","fpr")
plot(perf,colorize=TRUE)
perf
ROCR::::.__C__prediction
roc_auc_1 <- ROCR::performance(pred,measure = "auc")
roc_auc_1
pred<-ROCR::prediction(y_test_pred,y_test)
perf<-ROCR::performance(pred,"tpr","fpr")
roc_auc_1 <- ROCR::performance(pred,measure = "auc")
View(roc_auc_1)
roc_auc_1@y.values
print(roc_auc_1@y.values)
pred<-ROCR::prediction(y_test_pred,y_test)
perf<-ROCR::performance(pred,"tpr","fpr")
plot(perf,colorize=TRUE)
roc_auc_1 <- ROCR::performance(pred,measure = "auc")
print(roc_auc_1@y.values)
View(pred)
pred@predictions[[1]]
View(y_test_pred)
y_test
y_train
knitr::opts_chunk$set(echo = TRUE)
#obteniendo directorio
#getwd()
# "b es el nombre de la variable que contiene los datos
# usted puede asignar cualquier nombre disponible como "datos" o "datos_autos"
# yo le puse "b" por simplicidad
b<-read.csv("./data/autos_ventas.csv",sep = ";")
#Imprimiento las primeras 5 filas
knitr::kable({
#df <- t(head(round(a,2), 5))
df <- t(head(b, 5))
colnames(df) <- sprintf("%02d", 1:ncol(df))
df
})
library(ggplot2)
# Renombrando columna Date
colnames(b)[1]<-"Date"
# Transformando en fecha
b$Date<- as.Date(b$Date,"%d/%m/%Y")
#Graficando
pl <- ggplot(b,aes(x=Date))
pl+ geom_line(aes(y=Car),color="blue")+geom_line(aes(y=Truck),color="darkred")+theme_minimal()+theme(axis.text.x=element_text(angle=90, hjust=1))#+scale_color_brewer(palette="Paired")
# Dividiendo datos en conjunto de entrenamiento y validación
# Como nuestros datos ya están ordenados por fecha es fácil hacerlo:
# usted puede simplemente tomar las primeras 274 filas y las ultimas 11
# yo utilice el año para ilustrar como se haría si no estuviera ordenado
library(lubridate)
train_set<-b[year(b$Date)< 2017,]
test_set<-b[year(b$Date) >= 2017,]
library(xtable)
# Modelo
model_1<- lm(Car ~ Time + Year+ Q1+ Q2+ Q3+
Inventories+CPI_New_Cars+CPI_Used_Cars+Gas_Prices+
Cons_Conf_Autos+Miles_Driven+Bank_Auto_Interest_Rate+
US_Population_millions+Unemployment+Disposible_Income_Capita_Real+
Saving_Capital+ Household_Debt_Capital+US_House_Price_Inflation+
Consumer_Confidence+RealGDP+Fed_Funds_Rate+US_Urban_CPI_Change+
Nonfarm_Payrolls,
data=train_set)
# Imprimiendo resultado
knitr::kable(xtable(summary(model_1)))
library(Metrics)
# Sacando predicciones
pred_train_1<-predict(model_1,train_set)
pred_test_1<-predict(model_1,test_set)
#Mean Absolute Error
mae1<-mae(test_set$Car,pred_test_1)
mae_train1<-mae(train_set$Car,pred_train_1)
print(paste("Train Error: ",mae_train1))
print(paste("Test Error: ",mae1))
train_set<-b[year(b$Date)< 2017,]
test_set<-b[year(b$Date) >= 2017,]
# Modelo
model_1<- lm(Truck ~ Time + Year+ Q1+ Q2+ Q3+
Inventories+CPI_New_Cars+CPI_Used_Cars+Gas_Prices+
Cons_Conf_Autos+Miles_Driven+Bank_Auto_Interest_Rate+
US_Population_millions+Unemployment+Disposible_Income_Capita_Real+
Saving_Capital+ Household_Debt_Capital+US_House_Price_Inflation+
Consumer_Confidence+RealGDP+Fed_Funds_Rate+US_Urban_CPI_Change+
Nonfarm_Payrolls,
data=train_set)
# Sacando predicciones
pred_train_1<-predict(model_1,train_set)
pred_test_1<-predict(model_1,test_set)
#Mean Absolute Error
mae1<-mae(test_set$Truck,pred_test_1)
mae_train1<-mae(train_set$Truck,pred_train_1)
print(paste("Train Error: ",mae_train1))
print(paste("Test Error: ",mae1))
train_set<-b[(year(b$Date)>=2010)&(year(b$Date)< 2017),]
test_set<-b[year(b$Date) >= 2017,]
# Modelo
model_2<- lm(Truck ~ Time + Year+ Q1+ Q2+ Q3+
Inventories+CPI_New_Cars+CPI_Used_Cars+Gas_Prices+
Cons_Conf_Autos+Miles_Driven+Bank_Auto_Interest_Rate+
US_Population_millions+Unemployment+Disposible_Income_Capita_Real+
Saving_Capital+ Household_Debt_Capital+US_House_Price_Inflation+
Consumer_Confidence+RealGDP+Fed_Funds_Rate+US_Urban_CPI_Change+
Nonfarm_Payrolls,
data=train_set)
# Sacando predicciones
pred_train_2<-predict(model_2,train_set)
pred_test_2<-predict(model_2,test_set)
#Mean Absolute Error
mae2<-mae(test_set$Truck,pred_test_2)
mae_train2<-mae(train_set$Truck,pred_train_2)
print(paste("Train Error: ",mae_train2))
print(paste("Test Error: ",mae2))
#Modelo
model_3<- lm(Truck~Time+Year+Q1+Q2+Q3+CPI_New_Cars+
+Cons_Conf_Autos+Miles_Driven+US_Population_millions+
Unemployment+Disposible_Income_Capita_Real+
US_House_Price_Inflation+Consumer_Confidence+RealGDP+
Fed_Funds_Rate+Nonfarm_Payrolls, data = train_set)
#Predicciones
pred_train_3<-predict(model_3,train_set)
pred_test_3<-predict(model_3,test_set)
#Error Absoluto Medio
mae_train3<-mae(y_train,pred_train_3)
#Modelo
model_3<- lm(Truck~Time+Year+Q1+Q2+Q3+CPI_New_Cars+
+Cons_Conf_Autos+Miles_Driven+US_Population_millions+
Unemployment+Disposible_Income_Capita_Real+
US_House_Price_Inflation+Consumer_Confidence+RealGDP+
Fed_Funds_Rate+Nonfarm_Payrolls, data = train_set)
#Datos Reales
y_train<-train_set$Truck
y_test<- test_set$Truck
#Predicciones
pred_train_3<-predict(model_3,train_set)
pred_test_3<-predict(model_3,test_set)
#Error Absoluto Medio
mae_train3<-mae(y_train,pred_train_3)
mae3<-mae(y_test,pred_test_3)
#Reportando error
print(paste("train set: ",mae_train3))
print(paste("test set: ",mae3))
X_train<-train_set[,c("Time","Year", "Q1","Q2","Q3",
"CPI_New_Cars", "Cons_Conf_Autos","Miles_Driven",
"US_Population_millions","Unemployment",
"Disposible_Income_Capita_Real",
"US_House_Price_Inflation",
"Consumer_Confidence","RealGDP","Fed_Funds_Rate",
"Nonfarm_Payrolls")]
X_test<-test_set[,c("Time","Year", "Q1","Q2","Q3",
"CPI_New_Cars",
"Cons_Conf_Autos","Miles_Driven",
"US_Population_millions","Unemployment",
"Disposible_Income_Capita_Real",
"US_House_Price_Inflation",
"Consumer_Confidence","RealGDP","Fed_Funds_Rate",
"Nonfarm_Payrolls")]
y_train<-train_set$Truck
y_test<- test_set$Truck
model_3<-cv.glmnet(as.matrix(X_train),as.matrix(y_train),
family="gaussian", alpha = 1, nlambda=25)
X_train<-train_set[,c("Time","Year", "Q1","Q2","Q3",
"CPI_New_Cars", "Cons_Conf_Autos","Miles_Driven",
"US_Population_millions","Unemployment",
"Disposible_Income_Capita_Real",
"US_House_Price_Inflation",
"Consumer_Confidence","RealGDP","Fed_Funds_Rate",
"Nonfarm_Payrolls")]
X_test<-test_set[,c("Time","Year", "Q1","Q2","Q3",
"CPI_New_Cars",
"Cons_Conf_Autos","Miles_Driven",
"US_Population_millions","Unemployment",
"Disposible_Income_Capita_Real",
"US_House_Price_Inflation",
"Consumer_Confidence","RealGDP","Fed_Funds_Rate",
"Nonfarm_Payrolls")]
y_train<-train_set$Truck
y_test<- test_set$Truck
model_4<-cv.glmnet(as.matrix(X_train),as.matrix(y_train),
family="gaussian", alpha = 1, nlambda=25)
library(glmnet)
X_train<-train_set[,c("Time","Year", "Q1","Q2","Q3",
"CPI_New_Cars", "Cons_Conf_Autos","Miles_Driven",
"US_Population_millions","Unemployment",
"Disposible_Income_Capita_Real",
"US_House_Price_Inflation",
"Consumer_Confidence","RealGDP","Fed_Funds_Rate",
"Nonfarm_Payrolls")]
X_test<-test_set[,c("Time","Year", "Q1","Q2","Q3",
"CPI_New_Cars",
"Cons_Conf_Autos","Miles_Driven",
"US_Population_millions","Unemployment",
"Disposible_Income_Capita_Real",
"US_House_Price_Inflation",
"Consumer_Confidence","RealGDP","Fed_Funds_Rate",
"Nonfarm_Payrolls")]
y_train<-train_set$Truck
y_test<- test_set$Truck
model_4<-cv.glmnet(as.matrix(X_train),as.matrix(y_train),
family="gaussian", alpha = 1, nlambda=25)
# Sacando predicciones
pred_train_4=predict(model_4, newx = as.matrix(X_train), s = "lambda.min")
pred_test_4=predict(model_4, newx=as.matrix(X_test), s = "lambda.min")
#Mean Absolute Error
mae_train4<-mae(y_train,pred_train_4)
mae4<-mae(y_test,pred_test_4)
# reportando errores
print(paste("train set: ",mae_train4))
print(paste("test set: ",mae4))
1
