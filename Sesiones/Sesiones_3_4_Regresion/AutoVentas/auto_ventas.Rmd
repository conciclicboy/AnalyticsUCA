---
title: "Regresión en series de tiempo"
author: "Eduardo Aguilar, UCA"
output:
  html_document:
    css: default.css
    theme: paper
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
  #pdf_document:
    #includes:
      #in_header: /AnalyticsStyles/default.sty
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Prediciendo ventas de autos en USA

## El contexto de negocios
La industria automovilística puede indicar el estado y dirección de la economía estadounidense. Después de los gastos en vivienda, los autos son los productos en los que más puede gastar un consumidor promedio. Las ventas de autos son un aproximado de la confianza del consumidor.

Debido a su nivel de relevancia en la economía norteamericana, no sería absurdo suponer que las ventas de autos pueden estar siendo influenciadas por factores macroeconómicos como el producto interno bruto y la tasa de desempleo, así como factores propios de la industria automovilística.

Una empresa que se dedica a fabricar accesorios para autos está interesada en saber cual es el mercado potencial que tendrán el próximo año. El departamento de finanzas hace sus proyecciones basados en el número de autos que se estima vender en el país, y hasta ese momento habían estado usando las ventas del último período anterior como la mejor aproximación a las ventas del siguiente período. Este año decidieron cambiar de estrategia encargando al departamento de analítica el diseño de una herramienta que les ayudara a determinar cuál sería el mercado.

## Los datos
La tabla que se presente fue diseñada tomando datos de varias fuentes, incluyendo al [Buró de Análisis Económico](https://www.bea.gov/), al [Departamento de Energía](https://www.energy.gov/), el sistema de información financiera [Bloomberg](https://www.bloomberg.com/), entre otros.

**Variables Independientes**

Nombre           | Descripción          | Fuente
:----------------|:---------------------|:-----------------------------------------
New Auto Sales   | Ventas de Carros     | [Ward's Autos](https://www.wardsauto.com)
New Truck Sales  | Ventas de Camiones   | [Ward's Autos](https://www.wardsauto.com)
Total            | Ventas Totales       | [Ward's Autos](https://www.wardsauto.com)

**Variables de la industria automotriz**

Nombre                          | Descripción                | Fuente
:-------------------------------|:---------------------------|:-----------------------------------------
Auto Inventories                | Inventarios                | [Buró de Análisis Económico](https://www.bea.gov/)
New Vehicle Price Inflation     | Inflación en Autos Nuevos  | [Buró Estadísticas Laborales](https://www.bls.gov)
Used Vehicle Price Inflation    | Inflación en Autos Viejos  | [Buró Estadísticas Laborales](https://www.bls.gov)
Gas Prices                      | Precio de Petróleo         |[Departamento de Energía](https://www.energy.gov/)
Consumer Confidence: Automobiles| Confianza Consumidor       | [Conference Board](https://www.conference-board.org/us/)
Miles Driven                    | Millas Manejadas           | [Dpt de Transporte](https://www.transportation.gov/)
New Car Interest Rate           | Tasa de interés para Carros| [Reserva Federal](https://www.wardsauto.com)

**Variables macroeconómicas y financieras**

Nombre               | Descripción               | Fuente
:--------------------|:--------------------------|:-----------------------------------------
US Population        | Población USA             | [Buró de Análisis Económico](https://www.bea.gov/)
Unemployment Rate    | Tasa de Desempleo         | [Bloomberg](https://www.bloomberg.com/)
Disposible Income    | Ingresos Disponibles      | [Buró de Análisis Económico](https://www.bea.gov/)
Household Savings    | Ahorros de Hogares        | [Buró de Análisis Económico](https://www.bea.gov/)
House Price Inflation| Inflación Precios de Casas| [Bloomberg](https://www.bloomberg.com/)
Consumer Confidence  | Confianza del consumidor  | [Conference Board](https://www.conference-board.org/us/)
GDP (Real)           | PIB Real                  | [Buró de Análisis Económico](https://www.bea.gov/)
Fed Funds Rate       | Tasa de la Reserva Federal| [Reserva Federal](https://www.federalreserve.gov/)
Inflation            | Inflación                 | [Buró Estadísticas Laborales](https://www.bls.gov)
Non Farm Payrolls    | Salarios sin Agricultura  | [Buró Estadísticas Laborales](https://www.bls.gov)



Leyendo los datos:

```{r, echo=FALSE}
#obteniendo directorio
#getwd()

# "b es el nombre de la variable que contiene los datos
# usted puede asignar cualquier nombre disponible como "datos" o "datos_autos"
# yo le puse "b" por simplicidad

b<-read.csv("./data/autos_ventas.csv",sep = ";")


#Imprimiento las primeras 5 filas

knitr::kable({
  #df <- t(head(round(a,2), 5))  
  df <- t(head(b, 5))
  colnames(df) <- sprintf("%02d", 1:ncol(df))
  df
})

```


Sobre los datos habrá que mencionar, que los valores de las variables dependientes Car, Truck y Total ha sido desplazada hacia atrás por 1 período, es decir, los valores correspondientes a enero son en realidad los valores que fueron obtenidos en el mes de febrero, más adelante se explicará la razón de esto.


Existen 5 variables extras que fueron creadas: Time, Year, Q1, Q2, Q3. En breve explicaremos porque se diseñaron estas variables.


## Exploración de Datos

### Tendencias a través del tiempo
En las series temporales, como su nombre lo dice, el tiempo es un factor importante, ya que este puede determinar el status de una variable. En los precios de las acciones, por ejemplo, se pueden observar períodos en los que el precio de la acción cotiza a la baja; mientras que en las ventas minoristas es natural ver temporadas en que se vende mucho o vende poco (pre y post navidad).

Entonces, lo primero que se hará es visualizar la tendencia de precios a lo largo del tiempo.

```{r,message=FALSE,warning=FALSE, echo=FALSE}
library(ggplot2)

# Renombrando columna Date 
colnames(b)[1]<-"Date"

# Transformando en fecha
b$Date<- as.Date(b$Date,"%d/%m/%Y")

#Graficando
pl <- ggplot(b,aes(x=Date))

pl+ geom_line(aes(y=Car),color="blue")+geom_line(aes(y=Truck),color="darkred")+theme_minimal()+theme(axis.text.x=element_text(angle=90, hjust=1))#+scale_color_brewer(palette="Paired")

```


Basado en la gráfica anterior podemos inferir que hay temporadas a lo largo del tiempo. En nuestro caso, como tenemos datos distribuidos trimestralmente, suena lógico pensar un efecto temporal cada trimestre. Es por ello que se incluyeron las variables categóricas Q1, Q2, Q3, etc. En nuestro caso dicha variable ya venía incluida en la base, eso sale más fácil hacerlo desde excel, pero tampoco es difícil calcularla directamente en R.

Ahora bien, de acuerdo a la gráfica anterior no parece haber ninguna anormalidad en la distribución de autos vendidos, sin embargo nunca está demás crear un histograma para ver si en efecto no hay valores extremos que pudieran arruinar el ajuste del modelo.


```{r,message=FALSE,warning=FALSE, echo=FALSE}

#Graficando Carros
pl<-ggplot(b,aes(x=Car))
pl+geom_histogram(bins=20,fill='blue',alpha=0.4,color="blue")+theme_minimal()

#Graficando Camiones
pl<-ggplot(b,aes(x=Truck))
pl+geom_histogram(bins=20,fill='blue',alpha=0.4,color="blue")+theme_minimal()

```

En efecto, no parece haber nada anormal con los datos. Si usted tuviera un dato anormalmente grande/pequeño, no debería incluirlo en el análisis (o incluirlo pero no con su valor original) porque los métodos probabilísticos como la regresión lineal no son lo suficientemente robustos para asumir este tipo de cambios bruscos sin verse afectados en su eficiencia.


### Diagramas de dispersión

Tenemos 18 variables independientes de naturaleza  macroeconómica o de la industria automotriz, de las cuales debemos entender cuales tienen relaciones aproximadamente lineales respecto al número de autos o camiones vendidos.

#### Autos

```{r, message=FALSE, warning=FALSE, echo=FALSE}
# Haremos esto en porciones porque el programa va tronar si hacemos todos los 
library(radiant.data)
visualize(dataset=b,
          xvar=c("Inventories", "CPI_New_Cars", "CPI_Used_Cars",
                 "Gas_Prices", "Cons_Conf_Autos", "Miles_Driven"),
          yvar="Car",
          type="scatter",
          custom=FALSE
)

visualize(dataset=b,
          xvar=c("Bank_Auto_Interest_Rate", "US_Population_millions", "Unemployment",
                 "Disposible_Income_Capita_Real", "Saving_Capital", "Household_Debt_Capital"),
          yvar="Car",
          type="scatter",
          custom=FALSE
)


visualize(dataset=b,
          xvar=c("US_House_Price_Inflation", "Consumer_Confidence", "RealGDP",
                 "Fed_Funds_Rate", "US_Urban_CPI_Change", "Nonfarm_Payrolls"),
          yvar="Car",
          type="scatter",
          custom=FALSE
)


```

Bien, de los gráficos anteriores podemos inferir que variables tienen correlaciones aproximadamente lineales con nuestros datos. Este proceso de exploración puede también ser efectuado sacando las correlaciones entre variables (esto último lo puede hacer en excel o en R, pero si son demasiados datos excel tronará).
Las variables que parecen relevantes son: Inventarios, CPI autos usados, Población, Desempleo, Capital Disponible (Disposible Income), Deuda de Hogares (Household Debt), Confianza del consumidor, PIB (GDP), Fed Funds Rate, Non Farm Payrolls.


#### Camiones

```{r, message=FALSE, warning=FALSE, echo=FALSE}
# Haremos esto en porciones porque el programa va tronar si hacemos todos los 

visualize(dataset=b,
          xvar=c("Inventories", "CPI_New_Cars", "CPI_Used_Cars",
                 "Gas_Prices", "Cons_Conf_Autos", "Miles_Driven"),
          yvar="Truck",
          type="scatter",
          custom=FALSE
)

visualize(dataset=b,
          xvar=c("Bank_Auto_Interest_Rate", "US_Population_millions", "Unemployment",
                 "Disposible_Income_Capita_Real", "Saving_Capital", "Household_Debt_Capital"),
          yvar="Truck",
          type="scatter",
          custom=FALSE
)


visualize(dataset=b,
          xvar=c("US_House_Price_Inflation", "Consumer_Confidence", "RealGDP",
                 "Fed_Funds_Rate", "US_Urban_CPI_Change", "Nonfarm_Payrolls"),
          yvar="Truck",
          type="scatter",
          custom=FALSE
)



```

En el caso de los camiones, las variables relevantes serían: CPI Carros Nuevos, Millas Manejadas (Miles Driven), Desempleo, Precios de Hogares, PIB (GDP).
Entonces, a partir de esos gráficos que ve que las variables explicativas difieren entre los dos tipos de vehículos, así que se vuelve sensato diseñar diferentes modelos.

## Separando datos
Los pronósticos en series de tiempo tienen una diferencia fundamental respecto a las series no temporales, y sí, como su nombre lo dice esa diferencia es el tiempo. Suponga que usted trabaja para una gestora de fondos de inversión, tiene 1,000 días de historia de los precios de las acciones y otros factores financieros, toma una muestra aleatoria de 800 días para construir un modelo e intenta predecir los restantes 200 días. ¿Cuál es el problema con este enfoque?

Cómo habrá notado, el problema con este tipo de muestras aleatorias es que estaría utilizando información futura para predecir precios del pasado, entonces es posible que el modelo funcionara bien en el entrenamiento y validación, pero no tendría resultados consistentes en la práctica. Para que los resultados teóricos y reales sean similares usted debe intentar representar la realidad lo mejor posible, es decir, entrenando con datos pasados y evaluando con datos futuros. Esto se logra eligiendo una fecha que divida dos ventanas de tiempo, la de entrenamiento y la de validación.

La siguiente imagen muestra como se haría la validación en varias capas, pero por simplicidad nosotros solo tomaremos la última capa para evaluar el desempeño.


![**Validacion en 4 capas**](k_fold.png)

Dicho de otro modo, nosotros entrenaremos con datos pasados a una fecha límite, y evaluaremos resultados con datos futuros a la misma fecha:

![**Validacion en serie de tiempo**](forward_chain.png)

Nosotros estamos interesados en predecir un año a futuro, así que nuestros datos de entrenamiento serán de 1994 hasta 2016, mientras que nuestros datos de evaluación serán solo de 2017.

```{r,echo=FALSE, message=FALSE, warning=FALSE}

# Dividiendo datos en conjunto de entrenamiento y validación
# Como nuestros datos ya están ordenados por fecha es fácil hacerlo:
# usted puede simplemente tomar las primeras 274 filas y las ultimas 11
# yo utilice el año para ilustrar como se haría si no estuviera ordenado
library(lubridate)
train_set<-b[year(b$Date)< 2017,]
test_set<-b[year(b$Date) >= 2017,]
```


## Modelo
Vamos a construir varios modelos y seleccionaremos el que funcione mejor.
Nuevamente, eso puede sonar a que estamos haciendo prueba y error, pero en efecto esto así es, usted raramente encontrará el mejor modelo a la primera iteración. Tampoco encontraremos el mejor modelo en esta sesión, pero pretenedemos acercarnos a una solución subóptima que sea mejor que una solución aleatoria.


### Modelo 1: Regresión Lineal
Comencemos por incluir todas las variables posibles para ver cuales son los resultados del modelo:

```{r,message=FALSE, warning=FALSE, echo=FALSE}
# Creando modelo
#model_1<- lm(formula = price ~ room_type + neighborhood + 
#             reviews +overall_satisfaction + accommodates +
#             bedrooms,data = train_set)


# Sacando predicciones
#pred_train_1=predict(model_1,train_set)#entrenamiento
#pred_test_1=predict(model_1,test_set)#evaluación

# Reportando modelo: usted solo necesita poner "summary(model)"
# Eso le entrega los resultados del modelo pero se imprime en formato feo
# Nosotros lo vamos a imprimir como una "xtable" en "knitr::kable"
#library(xtable)
#knitr::kable(xtable(summary(model_1)))

# Librerías de utilidad 
library(olsrr)
library(xtable)

# Modelo
model_1<- lm(Car ~ Time + Year+ Q1+ Q2+ Q3+
             CPI_Used_Cars+ Gas_Prices+ Miles_Driven+
             US_Population_millions+ Unemployment+
             Disposible_Income_Capita_Real+ Saving_Capital+
             Household_Debt_Capital+ RealGDP+ Fed_Funds_Rate+
             US_Urban_CPI_Change+ Nonfarm_Payrolls,
           data=train_set)

# Imprimiendo resultado
knitr::kable(xtable(summary(model_1)))

```

Aunque la mayoría de valores p son cercanos a cero, el modelo incluye algunas variables que no son estadísticamente significativas, lo cual es indicio que debemos reducir el número de variables. Veamos ahora cual es el Mean Square Error en los conjuntos de entrenamiento y validación:

```{r, echo=FALSE,warning=FALSE, message=FALSE }
library(Metrics)

train_set<-b[year(b$Date)< 2017,]
test_set<-b[year(b$Date) >= 2017,]

# Sacando predicciones
pred_train_1<-predict(model_1,train_set)
pred_test_1<-predict(model_1,test_set)

#Mean Absolute Error
mae1<-mae(test_set$Car,pred_test_1)
mae_train1<-mae(train_set$Car,pred_train_1)

print(paste("Train Error: ",mae_train1))
print(paste("Test Error: ",mae1))
```

Que la diferencia sea tan grande indica que el modelo está terriblemente sobreajustado a los datos de entrenamiento. Debemos entonces reducir este sobreajuste, para lo cual crearemos más modelos. Hay dos formas de reducirlo: limitando el número de variables; y en series de tiempo, limitando la ventana de entrenamiento.

### Modelo 2: Limitando el número de variables


Una técnica muy conocida para eliminar variables es utilizando Stepwise Backward Regression, que comienza con el modelo completo y elimina sucesivamente variables que no son significativas. Estos son los resultados al correrlo.

```{r, echo=FALSE, message=FALSE, warning=FALSE}

# Modelo
model_2<- lm(Car ~ Time + Year+ Q1+ Q2+ Q3+
             CPI_Used_Cars+ Gas_Prices+ Miles_Driven+
             US_Population_millions+ Unemployment+
             Disposible_Income_Capita_Real+ Saving_Capital+
             Household_Debt_Capital+ RealGDP+ Fed_Funds_Rate+
             US_Urban_CPI_Change+ Nonfarm_Payrolls,
           data=train_set)

# Creando modelo: stepwise backward regression
temporal<-ols_step_forward_p(model_1)
model_2<-temporal$model

#ols_step_forward_p(model_1)
#ols_step_both_aic()

# Imprimiendo resultado
#knitr::kable(xtable(summary(model_2)))


# Sacando predicciones
pred_train_2<-predict(model_2,train_set)
pred_test_2<-predict(model_2,test_set)

#Mean Absolute Error
mae2<-mae(test_set$Car,pred_test_2)
mae_train2<-mae(train_set$Car,pred_train_2)

print(paste("Train Error: ",mae_train2))
print(paste("Test Error: ",mae2))

```


### Modelo 3: Reduciendo variables aún más
Ahora bien, recordemos que en la fase de exploración habíamos seleccionado un conjunto de variables que tenían potencial de ser significativas dada su fuerte correlación con la variable objetivo. Si utilizamos el modelo completo con esas variables y luego hacemos eliminación sucesiva de variables (backward) obtenemos lo siguiente:

```{r,message=FALSE, warning=FALSE, echo=FALSE}
# Modelo

model_3<- lm(Car ~ Time + Year+ Q1+ Q2+ Q3+
               Inventories+CPI_Used_Cars+ US_Population_millions+
               Unemployment+ Disposible_Income_Capita_Real+
               Household_Debt_Capital+ Consumer_Confidence+ 
               RealGDP+ Fed_Funds_Rate+ Nonfarm_Payrolls,
           data=train_set)



# Eliminando variables
#temporal<-ols_step_backward_aic(model_3)
#model_3<-temporal$model

# Sacando predicciones
pred_train_3=predict(model_3,train_set)
pred_test_3=predict(model_3,test_set)

#Mean Absolute Error
mae3<-mae(test_set$Car,pred_test_3)
mae_train3<-mae(train_set$Car,pred_train_3)

#Reportando errores
print(paste("Train Error: ",mae_train3))
print(paste("Test Error: ",mae3))

# Imprimiendo resultado
#knitr::kable(xtable(summary(model_3)))
```

### Modelo 4: En desarrollo
```{r,message=FALSE, warning=FALSE, echo=FALSE}
#library(xgboost)

# XGBoost, a diferencia de lm, no convierte las variables categóricas que aparecen como
# caracteres a variables binarias (0/1). Tendremos que usar la codificación

# Primero vamos a definir las matrices de entrenamiento y evaluación
#X_train<- train_set[,c(colnames(vecindarios),colnames(tipos_cuarto),"reviews",
#                       "overall_satisfaction", "accommodates","bedrooms",
#                       "longitude", "latitude")]

#X_test<- test_set[,c(colnames(vecindarios),colnames(tipos_cuarto),"reviews",
#                       "overall_satisfaction", "accommodates","bedrooms",
#                     "longitude", "latitude")]

# Luego definimos los vectores de la variable dependiente
#y_train<- train_set$price
#y_test<-test_set$price

# Modelo
#model_4 <- xgboost(data = as.matrix(X_train), label = as.matrix(y_train), max.depth = 4, 
#                   eta = 0.3, nthread = 2, nrounds = 100, objective = "reg:linear",
#                   eval_metric="rmse",verbose = 0)

# Predicciones
#pred_train_4<-predict(model_4,as.matrix(X_train))
#pred_test_4<-predict(model_4,as.matrix(X_test))

```


## Evaluando los modelos


```{r,message=FALSE, warning=FALSE, echo=FALSE}

#Librería de métricas
#install.packages("Metrics")
#library(Metrics)
#mae1<-mae(test_set$price,pred_test_1)
#mae2<-mae(test_set$price,pred_test_2)
#mae3<-mae(test_set$price,pred_test_3)
#mae4<-mae(test_set$price,pred_test_4)

# Mostrando resultados
#print((paste("Modelo 1:", mae1)))
#print((paste("Modelo 2:", mae2)))
#print((paste("Modelo 3:", mae3)))
#print((paste("Modelo 4:", mae4)))

```

## Conclusiones (... en desarrollo)
*Blah Blah Blah
> Analítica de datos es un proceso iterativo, podríamos necesitar regresar a nuestros datos originales en cualquier momento y seleccionar nuevos atributos, así como diferentes herramientas de regresión y modelamiento.