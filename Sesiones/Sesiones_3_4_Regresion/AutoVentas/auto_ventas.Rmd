---
title: "Regresión en series de tiempo"
author: "Eduardo Aguilar, UCA"
output:
  html_document:
    css: default.css
    theme: paper
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
  #pdf_document:
    #includes:
      #in_header: /AnalyticsStyles/default.sty
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Prediciendo ventas de autos en USA

## El contexto de negocios
La industria automovilística puede indicar el estado y dirección de la economía estadounidense. Después de los gastos en vivienda, los autos son los productos en los que más puede gastar un consumidor promedio. Las ventas de autos son un aproximado de la confianza del consumidor.

Debido a su nivel de relevancia en la economía norteamericana, no sería absurdo suponer que las ventas de autos pueden estar siendo influenciadas por factores macroeconómicos como el producto interno bruto y la tasa de desempleo, así como factores propios de la industria automovilística.

Una empresa que se dedica a fabricar accesorios para autos está interesada en saber cual es el mercado potencial que tendrán el próximo año. El departamento de finanzas hace sus proyecciones basados en el número de autos que se estima vender en el país, y hasta ese momento habían estado usando las ventas del último período anterior como la mejor aproximación a las ventas del siguiente período. Este año decidieron cambiar de estrategia encargando al departamento de analítica el diseño de una herramienta que les ayudara a determinar cuál sería el mercado.

## Los datos
La tabla que se presente fue diseñada tomando datos de varias fuentes, incluyendo al [Buró de Análisis Económico](https://www.bea.gov/), al [Departamento de Energía](https://www.energy.gov/), el sistema de información financiera [Bloomberg](https://www.bloomberg.com/), entre otros.

**Variables Independientes**

Nombre           | Descripción          | Fuente
:----------------|:---------------------|:-----------------------------------------
New Auto Sales   | Ventas de Carros     | [Ward's Autos](https://www.wardsauto.com)
New Truck Sales  | Ventas de Camiones   | [Ward's Autos](https://www.wardsauto.com)
Total            | Ventas Totales       | [Ward's Autos](https://www.wardsauto.com)

**Variables de la industria automotriz**

Nombre                          | Descripción                | Fuente
:-------------------------------|:---------------------------|:-----------------------------------------
Auto Inventories                | Inventarios                | [Buró de Análisis Económico](https://www.bea.gov/)
New Vehicle Price Inflation     | Inflación en Autos Nuevos  | [Buró Estadísticas Laborales](https://www.bls.gov)
Used Vehicle Price Inflation    | Inflación en Autos Viejos  | [Buró Estadísticas Laborales](https://www.bls.gov)
Gas Prices                      | Precio de Petróleo         |[Departamento de Energía](https://www.energy.gov/)
Consumer Confidence: Automobiles| Confianza Consumidor       | [Conference Board](https://www.conference-board.org/us/)
Miles Driven                    | Millas Manejadas           | [Dpt de Transporte](https://www.transportation.gov/)
New Car Interest Rate           | Tasa de interés para Carros| [Reserva Federal](https://www.wardsauto.com)

**Variables macroeconómicas y financieras**

Nombre               | Descripción               | Fuente
:--------------------|:--------------------------|:-----------------------------------------
US Population        | Población USA             | [Buró de Análisis Económico](https://www.bea.gov/)
Unemployment Rate    | Tasa de Desempleo         | [Bloomberg](https://www.bloomberg.com/)
Disposible Income    | Ingresos Disponibles      | [Buró de Análisis Económico](https://www.bea.gov/)
Household Savings    | Ahorros de Hogares        | [Buró de Análisis Económico](https://www.bea.gov/)
House Price Inflation| Inflación Precios de Casas| [Bloomberg](https://www.bloomberg.com/)
Consumer Confidence  | Confianza del consumidor  | [Conference Board](https://www.conference-board.org/us/)
GDP (Real)           | PIB Real                  | [Buró de Análisis Económico](https://www.bea.gov/)
Fed Funds Rate       | Tasa de la Reserva Federal| [Reserva Federal](https://www.federalreserve.gov/)
Inflation            | Inflación                 | [Buró Estadísticas Laborales](https://www.bls.gov)
Non Farm Payrolls    | Salarios sin Agricultura  | [Buró Estadísticas Laborales](https://www.bls.gov)



Leyendo los datos:

```{r, echo=FALSE}
#obteniendo directorio
#getwd()
  
b<-read.csv("./data/autos_ventas.csv",sep = ";")


#Imprimiento las primeras 5 filas

knitr::kable({
  #df <- t(head(round(a,2), 5))  
  df <- t(head(b, 5))
  colnames(df) <- sprintf("%02d", 1:ncol(df))
  df
})

```


Sobre los datos habrá que mencionar, que los valores de las variables dependientes Car, Truck y Total ha sido desplazada hacia atrás por 1 período, es decir, los valores correspondientes a enero son en realidad los valores que fueron obtenidos en el mes de febrero, más adelante se explicará la razón de esto.


Existen 5 variables extras que fueron creadas: Time, Year, Q1, Q2, Q3. En breve explicaremos porque se diseñaron estas variables.


## Exploración de Datos

### Tendencias a través del tiempo
En las series temporales, como su nombre lo dice, el tiempo es un factor importante, ya que este puede determinar el status de una variable. En los precios de las acciones, por ejemplo, se pueden observar períodos en los que el precio de la acción cotiza a la baja; mientras que en las ventas minoristas es natural ver temporadas en que se vende mucho o vende poco (pre y post navidad).

Entonces, lo primero que se hará es visualizar la tendencia de precios a lo largo del tiempo.

```{r,message=FALSE,warning=FALSE, echo=FALSE}
library(ggplot2)

# Renombrando columna Date 
colnames(b)[1]<-"Date"

# Transformando en fecha
b$Date<- as.Date(b$Date,"%d/%m/%Y")

#Graficando
pl <- ggplot(b,aes(x=Date))

pl+ geom_line(aes(y=Car),color="blue")+geom_line(aes(y=Truck),color="darkred")+theme_minimal()+theme(axis.text.x=element_text(angle=90, hjust=1))#+scale_color_brewer(palette="Paired")

```


Basado en la gráfica anterior podemos inferir que hay temporadas a lo largo del tiempo. En nuestro caso, como tenemos datos distribuidos trimestralmente, suena lógico pensar un efecto temporal cada trimestre. Es por ello que se incluyeron las variables categóricas Q1, Q2, Q3, etc. En nuestro caso dicha variable ya venía incluida en la base, eso sale más fácil hacerlo desde excel, pero tampoco es difícil calcularla directamente en R.

Ahora bien, de acuerdo a la gráfica anterior no parece haber ninguna anormalidad en la distribución de autos vendidos, sin embargo nunca está demás crear un histograma para ver si en efecto no hay valores extremos que pudieran arruinar el ajuste del modelo.


```{r,message=FALSE,warning=FALSE, echo=FALSE}

#Graficando Carros
pl<-ggplot(b,aes(x=Car))
pl+geom_histogram(bins=20,fill='blue',alpha=0.4,color="blue")+theme_minimal()

#Graficando Camiones
pl<-ggplot(b,aes(x=Truck))
pl+geom_histogram(bins=20,fill='blue',alpha=0.4,color="blue")+theme_minimal()

```

En efecto, no parece haber nada anormal con los datos. Si usted tuviera un dato anormalmente grande/pequeño, no debería incluirlo en el análisis (o incluirlo pero no con su valor original) porque los métodos probabilísticos como la regresión lineal no son lo suficientemente robustos para asumir este tipo de cambios bruscos sin verse afectados en su eficiencia.


### Diagramas de dispersión

Tenemos 18 variables independientes de naturaleza  macroeconómica o de la industria automotriz, de las cuales debemos entender cuales tienen relaciones aproximadamente lineales respecto al número de autos o camiones vendidos.

#### Autos

```{r, message=FALSE, warning=FALSE, echo=FALSE}
# Haremos esto en porciones porque el programa va tronar si hacemos todos los 
library(radiant.data)
visualize(dataset=b,
          xvar=c("Inventories", "CPI_New_Cars", "CPI_Used_Cars",
                 "Gas_Prices", "Cons_Conf_Autos", "Miles_Driven"),
          yvar="Car",
          type="scatter",
          custom=FALSE
)

visualize(dataset=b,
          xvar=c("Bank_Auto_Interest_Rate", "US_Population_millions", "Unemployment",
                 "Disposible_Income_Capita_Real", "Saving_Capital", "Household_Debt_Capital"),
          yvar="Car",
          type="scatter",
          custom=FALSE
)


visualize(dataset=b,
          xvar=c("US_House_Price_Inflation", "Consumer_Confidence", "RealGDP",
                 "Fed_Funds_Rate", "US_Urban_CPI_Change", "Nonfarm_Payrolls"),
          yvar="Car",
          type="scatter",
          custom=FALSE
)


```

Bien, de los gráficos anteriores podemos inferir que variables tienen correlaciones aproximadamente lineales con nuestros datos. Este proceso de exploración puede también ser efectuado sacando las correlaciones entre variables (esto último lo puede hacer en excel o en R, pero si son demasiados datos excel tronará).
Las variables que parecen relevantes son: Inventarios, CPI autos usados, Población, Desempleo, Capital Disponible (Disposible Income), Deuda de Hogares (Household Debt), Confianza del consumidor, PIB (GDP), Fed Funds Rate, Non Farm Payrolls.


#### Camiones

```{r, message=FALSE, warning=FALSE, echo=FALSE}
# Haremos esto en porciones porque el programa va tronar si hacemos todos los 
library(radiant.data)
visualize(dataset=b,
          xvar=c("Inventories", "CPI_New_Cars", "CPI_Used_Cars",
                 "Gas_Prices", "Cons_Conf_Autos", "Miles_Driven"),
          yvar="Truck",
          type="scatter",
          custom=FALSE
)

visualize(dataset=b,
          xvar=c("Bank_Auto_Interest_Rate", "US_Population_millions", "Unemployment",
                 "Disposible_Income_Capita_Real", "Saving_Capital", "Household_Debt_Capital"),
          yvar="Truck",
          type="scatter",
          custom=FALSE
)


visualize(dataset=b,
          xvar=c("US_House_Price_Inflation", "Consumer_Confidence", "RealGDP",
                 "Fed_Funds_Rate", "US_Urban_CPI_Change", "Nonfarm_Payrolls"),
          yvar="Truck",
          type="scatter",
          custom=FALSE
)



```

En el caso de los camiones, las variables relevantes serían: CPI Carros Nuevos, Millas Manejadas (Miles Driven), Desempleo, Precios de Hogares, PIB (GDP).

## Separando datos
Los pronósticos en series de tiempo tienen una diferencia fundamental respecto a las series no temporales, y sí, como su nombre lo dice esa diferencia es el tiempo. Suponga que usted trabaja para una gestora de fondos de inversión, tiene 1,000 días de historia de los precios de las acciones y otros factores financieros, toma una muestra aleatoria de 800 días para construir un modelo e intenta predecir los restantes 200 días. ¿Cuál es el problema conm este enfoque?

Cómo habrá notado, el problema con este tipo de muestras aleatorias es que estaría utilizando información futura para predecir precios del pasado



toma todos los datos y crea un modelo con una precisión casi perfecta que le permitiría predecir el precio de los alquileres de airbnb. ¿Tomaría usted la decisión de implementarlo inmediatamente?
Por supuesto que es una decisión personal sin una respuesta correcta, pero en la práctica no se recomienda hacer eso. La razón es que todos los modelos deben ser validados estadísticamente para estar seguro que su funcionamiento sea consistente en el tiempo.
Más adelante veremos a detalle esta técnica, pero en este momento, simplemente dividiremos los datos en dos grupos: uno con el 90% y otro con el 10%.

Antes de hacer eso vamos a codificar las variables categóricas con One Hot encoding.
Los modelos base de R como linear model (lm) pueden lidiar con variables categóricas fácilmente. Sin embargo, otro tipo de modelos no tiene esa funcionalidad, así que implementaremos esto desde antes:

```{r}
# One Hot Encoding
#vecindarios<-model.matrix(~neighborhood-1,head(b))
#tipos_cuarto<-model.matrix(~room_type-1,head(b))
#b <- cbind(b, vecindarios,tipos_cuarto)
```


Ahora podemos proceder a separar los datos:
```{r}
# Please ENTER the percentage of data used for estimation
porcion_train = 0.9
porcion_test = 0.1

# Librería dplyr
library(dplyr)

# Creando índice con función "mutate"" de dplyr
# Esto lo utilizaremos solo como referencia
#b <- mutate(b,id = row_number())

# Creando datos de entrenamiento con función "sample_frac" de dplyr
# La función toma una muestra aleatoria de tamaño "porcion_train" de "b"
#train_set <- sample_frac(b,porcion_train)

# Creando datos de evaluación con función "anti_join" de dplyr
# La función extraen los datos de "b" que no coinciden con "train_set"
# usando como referencia la columna "id"
#test_set <- anti_join(b, train_set, by = 'id')
```

Al tener listos los datos, podemos pasar a crear nuestro modelo con los datos de entrenamiento (train_set).

## Modelo
Vamos a construir varios modelos y seleccionaremos el que funcione mejor.
Nuevamente, eso puede sonar a que estamos haciendo prueba y error, pero en efecto esto así es, usted raramente encontrará el mejor modelo a la primera iteración. Tampoco encontraremos el mejor modelo en esta sesión, pero pretenedemos acercarnos a una solución subóptima que sea mejor que una solución aleatoria.


### Modelo 1: Regresión Lineal

```{r,message=FALSE, warning=FALSE }
# Creando modelo
#model_1<- lm(formula = price ~ room_type + neighborhood + 
#             reviews +overall_satisfaction + accommodates +
#             bedrooms,data = train_set)


# Sacando predicciones
#pred_train_1=predict(model_1,train_set)#entrenamiento
#pred_test_1=predict(model_1,test_set)#evaluación

# Reportando modelo: usted solo necesita poner "summary(model)"
# Eso le entrega los resultados del modelo pero se imprime en formato feo
# Nosotros lo vamos a imprimir como una "xtable" en "knitr::kable"
#library(xtable)
#knitr::kable(xtable(summary(model_1)))

```

La mayoría de variables son signioficativas con p-values pequeños.

### Modelo 2: Regresión log-lineal

```{r}
# Creando modelo
#model_2<-lm(formula = log(price) ~ room_type + neighborhood + 
#             reviews +overall_satisfaction + log(accommodates) +
#             bedrooms,data = train_set)

# Sacando predicciones
#pred_train_2=exp(predict(model_2,train_set))
#pred_test_2=exp(predict(model_2,test_set))

# Reportando modelo
#knitr::kable(xtable(summary(model_2)))
```


### Modelo 3: Arbol de regresión


```{r,message=FALSE, warning=FALSE}
library(rpart)
#model_3 <- rpart(price ~ room_type + neighborhood + 
#             reviews +overall_satisfaction + accommodates +
#             bedrooms,data = train_set, method="anova")

# Sacando predicciones
#pred_train_3=predict(model_3,train_set)#entrenamiento
#pred_test_3=predict(model_3,test_set)#evaluación
```

### Modelo 4: XGBoost
```{r,message=FALSE, warning=FALSE}
library(xgboost)

# XGBoost, a diferencia de lm, no convierte las variables categóricas que aparecen como
# caracteres a variables binarias (0/1). Tendremos que usar la codificación

# Primero vamos a definir las matrices de entrenamiento y evaluación
#X_train<- train_set[,c(colnames(vecindarios),colnames(tipos_cuarto),"reviews",
#                       "overall_satisfaction", "accommodates","bedrooms",
#                       "longitude", "latitude")]

#X_test<- test_set[,c(colnames(vecindarios),colnames(tipos_cuarto),"reviews",
#                       "overall_satisfaction", "accommodates","bedrooms",
#                     "longitude", "latitude")]

# Luego definimos los vectores de la variable dependiente
#y_train<- train_set$price
#y_test<-test_set$price

# Modelo
#model_4 <- xgboost(data = as.matrix(X_train), label = as.matrix(y_train), max.depth = 4, 
#                   eta = 0.3, nthread = 2, nrounds = 100, objective = "reg:linear",
#                   eval_metric="rmse",verbose = 0)

# Predicciones
#pred_train_4<-predict(model_4,as.matrix(X_train))
#pred_test_4<-predict(model_4,as.matrix(X_test))

```


## Evaluando los modelos
Luego de ajustar el/los modelo/s debemos evaluar el desempeño de los mismos. Para el caso de la regresión, la métrica a utilizar es llamada MAE (Mean Absolute Error) que en inglés significa Error Absoluto Medio.

Ciertamente para el caso de la regresión lineal se deben evaluar muchos otros factores para asegurar la significancia estadística del modelo como normalidad, homecedasticidad, etc. Sin embargo, a la hora de comparar un modelo lineal con uno no lineal, no se pueden utilizar todos estos factores ya que no son parte de los supuestos. Es por eso que nos enfocaremos solamente en la desviación absoluta media.

```{r,message=FALSE, warning=FALSE}

#Librería de métricas
#install.packages("Metrics")
#library(Metrics)
#mae1<-mae(test_set$price,pred_test_1)
#mae2<-mae(test_set$price,pred_test_2)
#mae3<-mae(test_set$price,pred_test_3)
#mae4<-mae(test_set$price,pred_test_4)

# Mostrando resultados
#print((paste("Modelo 1:", mae1)))
#print((paste("Modelo 2:", mae2)))
#print((paste("Modelo 3:", mae3)))
#print((paste("Modelo 4:", mae4)))

```


## Modelo 5: Ensamblando modelos 1 y 2 con los datos
Una técnica común en ciencia de datos es ensamblar modelos. La idea es seleccionar el resultado de modelos diferentes y construir en base a ellos un modelo que tenga un desempeño superior.

```{r, warning=FALSE, message=FALSE}

# Primero vamos a añadir a X_train y X_test los resultados del modelo lineal
#y_1<- as.matrix(pred_train_1)
#y_2<- as.matrix(pred_train_2)
#X_train_2<-cbind(X_train,y_1,y_2)

#y_1<- as.matrix(pred_test_1)
#y_2<- as.matrix(pred_test_2)
#X_test_2<-cbind(X_test, y_1,y_2)

# Modelo
#model_5 <- xgboost(data = as.matrix(X_train_2), label = as.matrix(y_train), max.depth = 4, 
#                   eta = 0.3, nthread = 2, nrounds = 120, objective = "reg:linear",
#                   eval_metric="rmse", verbose = 0)

# Predicciones
#pred_train_5<-predict(model_5,as.matrix(X_train_2))
#pred_test_5<-predict(model_5,as.matrix(X_test_2))

# Error Medio
#mae5<-mae(test_set$price,pred_test_5)

# Mostrando Resultados
#print((paste("Modelo 5:", mae5)))

```

## Conclusiones
* Si se tienen modelos con resultados diferentes, es posible construir un modelo final que sea capaz de superar modelos anteriores simplemente ensamblando los resultados y aplicando XGboost.

* Las propiedades de homocedasticidad y pvalues son importantes mientras se considere únicamente modelos lineales que asuman normalidad, para modelos de regresión que no sean lineales la métrica de comparación más apropiada sería la desviación absoluta media o la desviación cuadrática media.

* Para mejorar los resultados debemos mejorar el análisis exploratorio, construir nuevas variables o mejorar los datos iniciales.

> Analítica de datos es un proceso iterativo, podríamos necesitar regresar a nuestros datos originales en cualquier momento y seleccionar nuevos atributos, así como diferentes herramientas de regresión y modelamiento.