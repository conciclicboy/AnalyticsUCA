---
title: "Regresión en series de tiempo"
author: "Eduardo Aguilar, UCA"
output:
  html_document:
    css: default.css
    theme: paper
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
  #pdf_document:
    #includes:
      #in_header: /AnalyticsStyles/default.sty
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Prediciendo ventas de autos en USA

## El contexto de negocios
La industria automovilística puede indicar el estado y dirección de la economía estadounidense. Después de los gastos en vivienda, los autos son los productos en los que más puede gastar un consumidor promedio. Las ventas de autos son un aproximado de la confianza del consumidor.

Debido a su nivel de relevancia en la economía norteamericana, no sería absurdo suponer que las ventas de autos pueden estar siendo influenciadas por factores macroeconómicos como el producto interno bruto y la tasa de desempleo, así como factores propios de la industria automovilística.

Una empresa que se dedica a fabricar accesorios para autos está interesada en saber cual es el mercado potencial que tendrán el próximo año. El departamento de finanzas hace sus proyecciones basados en el número de autos que se estima vender en el país, y hasta ese momento habían estado usando las ventas del último período anterior como la mejor aproximación a las ventas del siguiente período. Este año decidieron cambiar de estrategia encargando al departamento de analítica el diseño de una herramienta que les ayudara a determinar cuál sería el mercado.

## Los datos
La tabla que se presente fue diseñada tomando datos de varias fuentes, incluyendo al [Buró de Análisis Económico](https://www.bea.gov/), al [Departamento de Energía](https://www.energy.gov/), el sistema de información financiera [Bloomberg](https://www.bloomberg.com/), entre otros.

**Variables Independientes**

Nombre           | Descripción          | Fuente
:----------------|:---------------------|:-----------------------------------------
New Auto Sales   | Ventas de Carros     | [Ward's Autos](https://www.wardsauto.com)
New Truck Sales  | Ventas de Camiones   | [Ward's Autos](https://www.wardsauto.com)
Total            | Ventas Totales       | [Ward's Autos](https://www.wardsauto.com)

**Variables de la industria automotriz**

Nombre                          | Descripción                | Fuente
:-------------------------------|:---------------------------|:-----------------------------------------
Auto Inventories                | Inventarios                | [Buró de Análisis Económico](https://www.bea.gov/)
New Vehicle Price Inflation     | Inflación en Autos Nuevos  | [Buró Estadísticas Laborales](https://www.bls.gov)
Used Vehicle Price Inflation    | Inflación en Autos Viejos  | [Buró Estadísticas Laborales](https://www.bls.gov)
Gas Prices                      | Precio de Petróleo         |[Departamento de Energía](https://www.energy.gov/)
Consumer Confidence: Automobiles| Confianza Consumidor       | [Conference Board](https://www.conference-board.org/us/)
Miles Driven                    | Millas Manejadas           | [Dpt de Transporte](https://www.transportation.gov/)
New Car Interest Rate           | Tasa de interés para Carros| [Reserva Federal](https://www.wardsauto.com)

**Variables macroeconómicas y financieras**

Nombre               | Descripción               | Fuente
:--------------------|:--------------------------|:-----------------------------------------
US Population        | Población USA             | [Buró de Análisis Económico](https://www.bea.gov/)
Unemployment Rate    | Tasa de Desempleo         | [Bloomberg](https://www.bloomberg.com/)
Disposible Income    | Ingresos Disponibles      | [Buró de Análisis Económico](https://www.bea.gov/)
Household Savings    | Ahorros de Hogares        | [Buró de Análisis Económico](https://www.bea.gov/)
House Price Inflation| Inflación Precios de Casas| [Bloomberg](https://www.bloomberg.com/)
Consumer Confidence  | Confianza del consumidor  | [Conference Board](https://www.conference-board.org/us/)
GDP (Real)           | PIB Real                  | [Buró de Análisis Económico](https://www.bea.gov/)
Fed Funds Rate       | Tasa de la Reserva Federal| [Reserva Federal](https://www.federalreserve.gov/)
Inflation            | Inflación                 | [Buró Estadísticas Laborales](https://www.bls.gov)
Non Farm Payrolls    | Salarios sin Agricultura  | [Buró Estadísticas Laborales](https://www.bls.gov)



Leyendo los datos:

```{r, echo=FALSE}
#obteniendo directorio
#getwd()

# "b es el nombre de la variable que contiene los datos
# usted puede asignar cualquier nombre disponible como "datos" o "datos_autos"
# yo le puse "b" por simplicidad

b<-read.csv("./data/autos_ventas.csv",sep = ";")


#Imprimiento las primeras 5 filas

knitr::kable({
  #df <- t(head(round(a,2), 5))  
  df <- t(head(b, 5))
  colnames(df) <- sprintf("%02d", 1:ncol(df))
  df
})

```


Sobre los datos habrá que mencionar, que los valores de las variables dependientes Car, Truck y Total ha sido desplazada hacia atrás por 1 período, es decir, los valores correspondientes a enero son en realidad los valores que fueron obtenidos en el mes de febrero, más adelante se explicará la razón de esto.


Existen 5 variables extras que fueron creadas: Time, Year, Q1, Q2, Q3. En breve explicaremos porque se diseñaron estas variables.


## Exploración de Datos

### Tendencias a través del tiempo
En las series temporales, como su nombre lo dice, el tiempo es un factor importante, ya que este puede determinar el status de una variable. En los precios de las acciones, por ejemplo, se pueden observar períodos en los que el precio de la acción cotiza a la baja; mientras que en las ventas minoristas es natural ver temporadas en que se vende mucho o vende poco (pre y post navidad).

Entonces, lo primero que se hará es visualizar la tendencia de precios a lo largo del tiempo.

```{r,message=FALSE,warning=FALSE, echo=FALSE}
library(ggplot2)

# Renombrando columna Date 
colnames(b)[1]<-"Date"

# Transformando en fecha
b$Date<- as.Date(b$Date,"%d/%m/%Y")

#Graficando
pl <- ggplot(b,aes(x=Date))

pl+ geom_line(aes(y=Car),color="blue")+geom_line(aes(y=Truck),color="darkred")+theme_minimal()+theme(axis.text.x=element_text(angle=90, hjust=1))#+scale_color_brewer(palette="Paired")

```


Basado en la gráfica anterior podemos inferir que hay temporadas a lo largo del tiempo. En nuestro caso, como tenemos datos distribuidos trimestralmente, suena lógico pensar un efecto temporal cada trimestre. Es por ello que se incluyeron las variables categóricas Q1, Q2, Q3, etc. En nuestro caso dicha variable ya venía incluida en la base, eso sale más fácil hacerlo desde excel, pero tampoco es difícil calcularla directamente en R.

Ahora bien, de acuerdo a la gráfica anterior no parece haber ninguna anormalidad en la distribución de autos vendidos, sin embargo nunca está demás crear un histograma para ver si en efecto no hay valores extremos que pudieran arruinar el ajuste del modelo.


```{r,message=FALSE,warning=FALSE, echo=FALSE}

#Graficando Carros
pl<-ggplot(b,aes(x=Car))
pl+geom_histogram(bins=20,fill='blue',alpha=0.4,color="blue")+theme_minimal()

#Graficando Camiones
pl<-ggplot(b,aes(x=Truck))
pl+geom_histogram(bins=20,fill='blue',alpha=0.4,color="blue")+theme_minimal()

```

En efecto, no parece haber nada anormal con los datos. Si usted tuviera un dato anormalmente grande/pequeño, no debería incluirlo en el análisis (o incluirlo pero no con su valor original) porque los métodos probabilísticos como la regresión lineal no son lo suficientemente robustos para asumir este tipo de cambios bruscos sin verse afectados en su eficiencia.


### Diagramas de dispersión

Tenemos 18 variables independientes de naturaleza  macroeconómica o de la industria automotriz, de las cuales debemos entender cuales tienen relaciones aproximadamente lineales respecto al número de autos o camiones vendidos.

#### Autos

```{r, message=FALSE, warning=FALSE, echo=FALSE}
# Haremos esto en porciones porque el programa va tronar si hacemos todos los 
library(radiant.data)
visualize(dataset=b,
          xvar=c("Inventories", "CPI_New_Cars", "CPI_Used_Cars",
                 "Gas_Prices", "Cons_Conf_Autos", "Miles_Driven"),
          yvar="Car",
          type="scatter",
          custom=FALSE
)

visualize(dataset=b,
          xvar=c("Bank_Auto_Interest_Rate", "US_Population_millions", "Unemployment",
                 "Disposible_Income_Capita_Real", "Saving_Capital", "Household_Debt_Capital"),
          yvar="Car",
          type="scatter",
          custom=FALSE
)


visualize(dataset=b,
          xvar=c("US_House_Price_Inflation", "Consumer_Confidence", "RealGDP",
                 "Fed_Funds_Rate", "US_Urban_CPI_Change", "Nonfarm_Payrolls"),
          yvar="Car",
          type="scatter",
          custom=FALSE
)


```

Bien, de los gráficos anteriores podemos inferir que variables tienen correlaciones aproximadamente lineales con nuestros datos. Este proceso de exploración puede también ser efectuado sacando las correlaciones entre variables (esto último lo puede hacer en excel o en R, pero si son demasiados datos excel tronará).
Las variables que parecen relevantes son: Inventarios, CPI autos usados, Población, Desempleo, Capital Disponible (Disposible Income), Deuda de Hogares (Household Debt), Confianza del consumidor, PIB (GDP), Fed Funds Rate, Non Farm Payrolls.


#### Camiones

```{r, message=FALSE, warning=FALSE, echo=FALSE}
# Haremos esto en porciones porque el programa va tronar si hacemos todos los 

visualize(dataset=b,
          xvar=c("Inventories", "CPI_New_Cars", "CPI_Used_Cars",
                 "Gas_Prices", "Cons_Conf_Autos", "Miles_Driven"),
          yvar="Truck",
          type="scatter",
          custom=FALSE
)

visualize(dataset=b,
          xvar=c("Bank_Auto_Interest_Rate", "US_Population_millions", "Unemployment",
                 "Disposible_Income_Capita_Real", "Saving_Capital", "Household_Debt_Capital"),
          yvar="Truck",
          type="scatter",
          custom=FALSE
)


visualize(dataset=b,
          xvar=c("US_House_Price_Inflation", "Consumer_Confidence", "RealGDP",
                 "Fed_Funds_Rate", "US_Urban_CPI_Change", "Nonfarm_Payrolls"),
          yvar="Truck",
          type="scatter",
          custom=FALSE
)



```

En el caso de los camiones, las variables relevantes serían: CPI Carros Nuevos, Millas Manejadas (Miles Driven), Desempleo, Precios de Hogares, PIB (GDP).
Entonces, a partir de esos gráficos que ve que las variables explicativas difieren entre los dos tipos de vehículos, así que se vuelve sensato diseñar diferentes modelos.

## Separando datos
Los pronósticos en series de tiempo tienen una diferencia fundamental respecto a las series no temporales, y sí, como su nombre lo dice esa diferencia es el tiempo. Suponga que usted trabaja para una gestora de fondos de inversión, tiene 1,000 días de historia de los precios de las acciones y otros factores financieros, toma una muestra aleatoria de 800 días para construir un modelo e intenta predecir los restantes 200 días. ¿Cuál es el problema con este enfoque?

Cómo habrá notado, el problema con este tipo de muestras aleatorias es que estaría utilizando información futura para predecir precios del pasado, entonces es posible que el modelo funcionara bien en el entrenamiento y validación, pero no tendría resultados consistentes en la práctica. Para que los resultados teóricos y reales sean similares usted debe intentar representar la realidad lo mejor posible, es decir, entrenando con datos pasados y evaluando con datos futuros. Esto se logra eligiendo una fecha que divida dos ventanas de tiempo, la de entrenamiento y la de validación.

La siguiente imagen muestra como se haría la validación en varias capas, pero por simplicidad nosotros solo tomaremos la última capa para evaluar el desempeño.


![**Validacion en 4 capas**](k_fold.png)

Dicho de otro modo, nosotros entrenaremos con datos pasados a una fecha límite, y evaluaremos resultados con datos futuros a la misma fecha:

![**Validacion en serie de tiempo**](forward_chain.png)

Nosotros estamos interesados en predecir un año a futuro, así que nuestros datos de entrenamiento serán de 1994 hasta 2016, mientras que nuestros datos de evaluación serán solo de 2017.

```{r,echo=FALSE, message=FALSE, warning=FALSE}

# Dividiendo datos en conjunto de entrenamiento y validación
# Como nuestros datos ya están ordenados por fecha es fácil hacerlo:
# usted puede simplemente tomar las primeras 274 filas y las ultimas 11
# yo utilice el año para ilustrar como se haría si no estuviera ordenado
library(lubridate)
train_set<-b[year(b$Date)< 2017,]
test_set<-b[year(b$Date) >= 2017,]
```


## Autos
Vamos a construir varios modelos y seleccionaremos el que funcione mejor.
Nuevamente, eso puede sonar a que estamos haciendo prueba y error, pero en efecto esto así es, usted raramente encontrará el mejor modelo a la primera iteración. Tampoco encontraremos el mejor modelo en esta sesión, pero pretenedemos acercarnos a una solución subóptima que sea mejor que una solución aleatoria.

### Modelo 1: Regresión Lineal
Comencemos por incluir todas las variables posibles y todos los datos de entrenamiento desde 1994 hasta 2016. Estos son los resultados del modelo:

```{r,message=FALSE, warning=FALSE, echo=FALSE}
# Creando modelo
#model_1<- lm(formula = price ~ room_type + neighborhood + 
#             reviews +overall_satisfaction + accommodates +
#             bedrooms,data = train_set)


# Sacando predicciones
#pred_train_1=predict(model_1,train_set)#entrenamiento
#pred_test_1=predict(model_1,test_set)#evaluación

# Reportando modelo: usted solo necesita poner "summary(model)"
# Eso le entrega los resultados del modelo pero se imprime en formato feo
# Nosotros lo vamos a imprimir como una "xtable" en "knitr::kable"
#library(xtable)
#knitr::kable(xtable(summary(model_1)))

# Librerías de utilidad 
library(olsrr)
library(xtable)

# Modelo
model_1<- lm(Car ~ Time + Year+ Q1+ Q2+ Q3+
             CPI_Used_Cars+ Gas_Prices+ Miles_Driven+
             US_Population_millions+ Unemployment+
             Disposible_Income_Capita_Real+ Saving_Capital+
             Household_Debt_Capital+ RealGDP+ Fed_Funds_Rate+
             US_Urban_CPI_Change+ Nonfarm_Payrolls,
           data=train_set)

# Imprimiendo resultado
knitr::kable(xtable(summary(model_1)))
```

Aunque la mayoría de valores p son cercanos a cero, el modelo incluye algunas variables que no son estadísticamente significativas, lo cual es indicio que debemos reducir el número de variables. Veamos ahora cual es el Mean Square Error en los conjuntos de entrenamiento y validación:

```{r, echo=FALSE,warning=FALSE, message=FALSE }
library(Metrics)

#train_set<-b[year(b$Date)< 2017,]
#test_set<-b[year(b$Date) >= 2017,]

# Sacando predicciones
pred_train_1<-predict(model_1,train_set)
pred_test_1<-predict(model_1,test_set)

#Mean Absolute Error
mae1<-mae(test_set$Car,pred_test_1)
mae_train1<-mae(train_set$Car,pred_train_1)

print(paste("Train Error: ",mae_train1))
print(paste("Test Error: ",mae1))
```

Que la diferencia sea tan grande indica que el modelo está terriblemente sobreajustado a los datos de entrenamiento. Debemos entonces reducir este sobreajuste, para lo cual crearemos más modelos. Hay dos formas de reducirlo: limitando el número de variables; y en series de tiempo, limitando la ventana de entrenamiento.


### Modelo 2: Reduciendo ventana de entrenamiento

Un detalle en particular con las series de tiempo es que las relaciones son dinámicas y las tendencias cambian a lo largo de los años: hay crisis y buenos tiempos. En ese sentido debemos limitar la ventana temporal de entrenamiento, pues no siempre se encontrarán las mismas características. Analizando la historia, recordemos que tuvimos dos períodos de crisis en los úlimos 20 años, la burbuja **.com** en 2000-2001 y la crisis hipotecaria del 2008, cuyo impacto duró hasta medidados de 2009. Definamos entonces, un período de entrenamiento desde un año "X" hasta 2016 y uno de evaluación del año 2017 entrenando nuevamente el modelo con todas las variables.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(glmnet)


train_set<-b[(year(b$Date)>=2010)&(year(b$Date)< 2017),]
test_set<-b[year(b$Date) >= 2017,]


X_train<-train_set[,c("Time","Year", "Q1", "Q2", "Q3",
                   "CPI_Used_Cars", "Gas_Prices", "Miles_Driven",
                   "US_Population_millions", "Unemployment", 
                   "Disposible_Income_Capita_Real", "Saving_Capital",
                   "Household_Debt_Capital", "RealGDP", "Fed_Funds_Rate",
                   "US_Urban_CPI_Change", "Nonfarm_Payrolls")]

X_test<-test_set[,c("Time","Year", "Q1", "Q2", "Q3",
                   "CPI_Used_Cars", "Gas_Prices", "Miles_Driven",
                   "US_Population_millions", "Unemployment", 
                   "Disposible_Income_Capita_Real", "Saving_Capital",
                   "Household_Debt_Capital", "RealGDP", "Fed_Funds_Rate",
                   "US_Urban_CPI_Change", "Nonfarm_Payrolls")]

y_train<-train_set$Car
y_test<- test_set$Car

#lambda <- 10^seq(10, -2, length = 100)

#model_2<-cv.glmnet(as.matrix(X_train),as.matrix(y_train),
#                family="gaussian", alpha = 0, nlambda=15)


model_2 <- lm(Car ~ Time + Year+ Q1+ Q2+ Q3+
             CPI_Used_Cars+ Gas_Prices+ Miles_Driven+
             US_Population_millions+ Unemployment+
             Disposible_Income_Capita_Real+ Saving_Capital+
             Household_Debt_Capital+ RealGDP+ Fed_Funds_Rate+
             US_Urban_CPI_Change+ Nonfarm_Payrolls,
           data=train_set)


# Sacando predicciones
pred_train_2<-predict(model_2,train_set)
pred_test_2<-predict(model_2,test_set)

#Mean Absolute Error
mae2<-mae(test_set$Car,pred_test_2)
mae_train2<-mae(train_set$Car,pred_train_2)

print(paste("Train Error: ",mae_train2))
print(paste("Test Error: ",mae2))

# Imprimiendo resultado
#knitr::kable(xtable(summary(model_2)))
```

Y mágicamente nuestro error se redujo en ambos conjuntos, entrenamiento y evaluación. Pero estos dos siguen aún siendo muy diferentes, lo que da indicios que aún podemos mejorar.

* ¿Puede usted imaginar que año se utilizó para este cálculo?
* ¿Pruebe con varias opciones para "X", porqué los resultados son tan similares o tan diferentes?


### Modelo 3: Limitando el número de variables (Regularizando)
Una técnica muy conocida para limitar el efecto de incluir demasiadas variables es Regularizando. La regularización reduce el efecto de incluir demasiadas variables en el modelo penalizando por cada variable extra. Los métodos más famosos son la Regresión Contraida (Ridge Regression) y Regresión Lasso. Al correr el modelo utilizando Lasso obtenemos los siguientes resultados:

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(glmnet)

X_train<-train_set[,c("Time","Year", "Q1", "Q2", "Q3",
                   "CPI_Used_Cars", "Gas_Prices", "Miles_Driven",
                   "US_Population_millions", "Unemployment", 
                   "Disposible_Income_Capita_Real", "Saving_Capital",
                   "Household_Debt_Capital", "RealGDP", "Fed_Funds_Rate",
                   "US_Urban_CPI_Change", "Nonfarm_Payrolls")]

X_test<-test_set[,c("Time","Year", "Q1", "Q2", "Q3",
                   "CPI_Used_Cars", "Gas_Prices", "Miles_Driven",
                   "US_Population_millions", "Unemployment", 
                   "Disposible_Income_Capita_Real", "Saving_Capital",
                   "Household_Debt_Capital", "RealGDP", "Fed_Funds_Rate",
                   "US_Urban_CPI_Change", "Nonfarm_Payrolls")]

y_train<-train_set$Car
y_test<- test_set$Car

#lambda <- 10^seq(10, -2, length = 100)

model_2<-cv.glmnet(as.matrix(X_train),as.matrix(y_train),
                family="gaussian", alpha = 1, nlambda=15)

# Sacando predicciones
pred_train_2=predict(model_2, newx = as.matrix(X_train), s = "lambda.min")
pred_test_2=predict(model_2, newx = as.matrix(X_test), s = "lambda.min")

#Mean Absolute Error
mae_train2<-mae(train_set$Car,pred_train_2)
mae2<-mae(test_set$Car,pred_test_2)

# reportando errores
print(paste("train set: ",mae_train2))
print(paste("test set: ",mae2))

# Imprimiendo resultado
#knitr::kable(xtable(summary(model_2)))
```

En este caso, hemos logrado reducir el error de evaluación y aumentado el error del entrenamiento, haciendo que el desempeño de ambos sea muy cercano. Esto indica que hemos optimizado nuestro **modelo lineal** con estas variables predictivas (no necesariamente el mejor modelo).



### Modelo 4: Utilizando la exploración visual.

Ahora bien, recordemos que en la fase de exploración habíamos seleccionado un conjunto de variables que tenían potencial de ser significativas dada su fuerte correlación con la variable objetivo. Si utilizamos el modelo completo con esas variables sin realizar ninguna regularización:

```{r,message=FALSE, warning=FALSE, echo=FALSE}
# Modelo

model_3<- lm(Car ~ Time + Year+ Q1+ Q2+ Q3+
               Inventories+CPI_Used_Cars+ US_Population_millions+
               Unemployment+ Disposible_Income_Capita_Real+
               Household_Debt_Capital+ Consumer_Confidence+ 
               RealGDP+ Fed_Funds_Rate+ Nonfarm_Payrolls,
           data=train_set)

# Sacando predicciones
pred_train_3=predict(model_3,train_set)
pred_test_3=predict(model_3,test_set)

#Mean Absolute Error
mae3<-mae(test_set$Car,pred_test_3)
mae_train3<-mae(train_set$Car,pred_train_3)

#Reportando errores
print(paste("Train Error: ",mae_train3))
print(paste("Test Error: ",mae3))

# Imprimiendo resultado
#knitr::kable(xtable(summary(model_3)))
```

En este caso, los resultados del modelo empeoraron. Esto se debe a que la regularización automáticamente eligió las variables con más poder predictivo, mientras que acá fue nuestro propio criterio y análisis explorativo lo que generó los resultados. Pero no nos desanimemos, muchas veces los mejores resultados se obtienen haciendo un cuidadoso análisis explorativo más que dejando los modelos correr como cajas negras.


## Camiones
Repitamos los mismos experimentos para los camiones

### Modelo 4: En desarrollo
```{r,message=FALSE, warning=FALSE, echo=FALSE}
#library(xgboost)

# XGBoost, a diferencia de lm, no convierte las variables categóricas que aparecen como
# caracteres a variables binarias (0/1). Tendremos que usar la codificación

# Primero vamos a definir las matrices de entrenamiento y evaluación
#X_train<- train_set[,c(colnames(vecindarios),colnames(tipos_cuarto),"reviews",
#                       "overall_satisfaction", "accommodates","bedrooms",
#                       "longitude", "latitude")]

#X_test<- test_set[,c(colnames(vecindarios),colnames(tipos_cuarto),"reviews",
#                       "overall_satisfaction", "accommodates","bedrooms",
#                     "longitude", "latitude")]

# Luego definimos los vectores de la variable dependiente
#y_train<- train_set$price
#y_test<-test_set$price

# Modelo
#model_4 <- xgboost(data = as.matrix(X_train), label = as.matrix(y_train), max.depth = 4, 
#                   eta = 0.3, nthread = 2, nrounds = 100, objective = "reg:linear",
#                   eval_metric="rmse",verbose = 0)

# Predicciones
#pred_train_4<-predict(model_4,as.matrix(X_train))
#pred_test_4<-predict(model_4,as.matrix(X_test))

```


## Conclusiones (... en desarrollo)

* Conclusión 1
* Conclusión 2


> Analítica de datos es un proceso iterativo, podríamos necesitar regresar a nuestros datos originales en cualquier momento y seleccionar nuevos atributos, así como diferentes herramientas de regresión y modelamiento.