make_pdf_file = 0 # Haga este número 1 si quiere un archivo PDF, 0 para HTML
print(getwd())
source("../../AnalyticsLibraries/library.R")
source("../../AnalyticsLibraries/heatmapOutput.R")
# Opciones de paquetes
ggthemr('fresh')  # tema de ggplot
opts_knit$set(progress=FALSE, verbose=FALSE)
opts_chunk$set(echo=FALSE, fig.align="center", fig.width=10, fig.height=6.2)
options(knitr.kable.NA = '')
make_pdf_file = 0 # Haga este número 1 si quiere un archivo PDF, 0 para HTML
print(getwd())
source("../../AnalyticsLibraries/library.R")
source("../../AnalyticsLibraries/heatmapOutput.R")
# Opciones de paquetes
ggthemr('fresh')  # tema de ggplot
opts_knit$set(progress=FALSE, verbose=FALSE)
opts_chunk$set(echo=FALSE, fig.align="center", fig.width=10, fig.height=6.2)
options(knitr.kable.NA = '')
make_pdf_file = 0 # Haga este número 1 si quiere un archivo PDF, 0 para HTML
print(getwd())
source("../../AnalyticsLibraries/library.R")
source("../../AnalyticsLibraries/heatmapOutput.R")
# Opciones de paquetes
ggthemr('fresh')  # tema de ggplot
opts_knit$set(progress=FALSE, verbose=FALSE)
opts_chunk$set(echo=FALSE, fig.align="center", fig.width=10, fig.height=6.2)
options(knitr.kable.NA = '')
# Por favor INGRESE el nombre del archivo
datafile_name = "../../Data/UCI_Credit_Card.csv"
ProjectData <- read.csv(datafile_name)
# Convertimos los datos a la clase data.matrix para que sea mas fácil de manipular
ProjectData <- data.matrix(ProjectData)
# Por favor INGRESE la variable dependiente(clase).
# Por favor use números, no nombres de columnas. Por ejemplo, 82 usa la columna en la posición 82 como la variable dependiente.
# Necesita asegurarse que la variable dependiente solo tome dos valores: 0 y 1.
dependent_variable = 25
# Por favor ingrese los atributos a usar como variables independientes.
# Por favor use números, no nombres de columnas. Por ejemplo, c(1:5, 7, 8) usa las columnas 1,2,3,4,5,7,8.
independent_variables = c(1:24) # usa todos los atributos disponibles
dependent_variable = unique(sapply(dependent_variable,function(i) min(ncol(ProjectData), max(i,1))))
independent_variables = unique(sapply(independent_variables,function(i) min(ncol(ProjectData), max(i,1))))
if (length(unique(ProjectData[,dependent_variable])) !=2){
cat("\n*****\n REVISE DE NUEVO, LA VARIABLE DEPENDIENTE TOMA MÁS DE 2 VALORES")
cat("\nDividiendo los datos respecto a la mediana...\n*****\n ")
new_dependent = ProjectData[,dependent_variable] >= median(ProjectData[,dependent_variable])
ProjectData[,dependent_variable] <- 1*new_dependent
}
# Por favor INGRESE el umbral de probabilidad arriba del cual una observación será categorizada como clase 1:
Probability_Threshold = 0.5 # entre 0 y 1
# Por favor INGRESE el porcentaje de datos usados para la estimación
estimation_data_percent = 80
validation_data_percent = 10
test_data_percent = 100-estimation_data_percent-validation_data_percent
# Por favor INGRESE 1 si quiere dividir los datos aleatoriamente en los conjuntos de estimación y validación/evaluación
random_sampling = 0
# Parámetros del árbol
# Por favor INGRESE el control de complejidad cp del árbol(CART), por ejemplo de 0.0001 a 0.02, dependiendo de los datos.
CART_cp = 0.0025
CART_control = rpart.control(cp = CART_cp)
# Por favor INGRESE el significado de las clases 1 y 0:
class_1_interpretation = "default"
class_0_interpretation = "no default"
# Por favor INGRESE los valores de ganancia/costo de clasificar correcta o incorrectamente los datos:
actual_1_predict_1 = 0
actual_1_predict_0 = -100000
actual_0_predict_1 = 0
actual_0_predict_0 = 20000
Profit_Matrix = matrix(c(actual_1_predict_1, actual_0_predict_1, actual_1_predict_0, actual_0_predict_0), ncol=2)
colnames(Profit_Matrix) <- c(paste("Predict 1 (", class_1_interpretation, ")", sep = ""), paste("Predict 0 (", class_0_interpretation, ")", sep = ""))
rownames(Profit_Matrix) <- c(paste("Actual 1 (", class_1_interpretation, ")", sep = ""), paste("Actual 0 (", class_0_interpretation, ")", sep = ""))
# Por favor INGRESE el máximo número de observaciones a mostrar en el reporte y diapositivas
# (El número predefinido es 50. Si el número es demasiado grande el reporte y las diapositivas podrían no ser generados -  muy lento o no funcionará!!)
max_data_report = 10
knitr::kable({
df <- t(head(round(ProjectData[,independent_variables],2), max_data_report))
colnames(df) <- sprintf("%02d", 1:ncol(df))
df
})
if (random_sampling){
estimation_data_ids=sample.int(nrow(ProjectData),floor(estimation_data_percent*nrow(ProjectData)/100))
non_estimation_data = setdiff(1:nrow(ProjectData),estimation_data_ids) #setdiff(x,y) returns the elements of x that are not in y
validation_data_ids=non_estimation_data[sample.int(length(non_estimation_data), floor(validation_data_percent/(validation_data_percent+test_data_percent)*length(non_estimation_data)))]
} else {
estimation_data_ids=1:floor(estimation_data_percent*nrow(ProjectData)/100)
non_estimation_data = setdiff(1:nrow(ProjectData),estimation_data_ids)
validation_data_ids = (tail(estimation_data_ids,1)+1):(tail(estimation_data_ids,1) + floor(validation_data_percent/(validation_data_percent+test_data_percent)*length(non_estimation_data)))
}
test_data_ids = setdiff(1:nrow(ProjectData), union(estimation_data_ids,validation_data_ids))
estimation_data=ProjectData[estimation_data_ids,]
validation_data=ProjectData[validation_data_ids,]
test_data=ProjectData[test_data_ids,]
class_percentages=matrix(c(sum(estimation_data[,dependent_variable]==1),sum(estimation_data[,dependent_variable]==0)), nrow=1); colnames(class_percentages)<-c("Class 1", "Class 0")
rownames(class_percentages)<-"# of Observations"
knitr::kable(class_percentages)
class_percentages=matrix(c(sum(validation_data[,dependent_variable]==1),sum(validation_data[,dependent_variable]==0)), nrow=1); colnames(class_percentages)<-c("Class 1", "Class 0")
rownames(class_percentages)<-"# of Observations"
knitr::kable(class_percentages)
knitr::kable(round(my_summary(estimation_data[estimation_data[,dependent_variable]==1,independent_variables]),2))
knitr::kable(round(my_summary(estimation_data[estimation_data[,dependent_variable]==0,independent_variables]),2))
# Please ENTER the selected independent variables for which to draw box plots.
# Please use numbers, not column names. E.g., c(1:5, 7, 8) uses columns 1,2,3,4,5,7,8.
boxplots_independent_variables = c(7:12) # use only the PAY_ variables
DVvalues = unique(estimation_data[,dependent_variable])
x0 = estimation_data[which(estimation_data[,dependent_variable]==DVvalues[1]),boxplots_independent_variables]
x1 = estimation_data[which(estimation_data[,dependent_variable]==DVvalues[2]),boxplots_independent_variables]
colnames(x0) <- 1:ncol(x0)
colnames(x1) <- 1:ncol(x1)
swatch.default <- as.character(swatch())
set_swatch(c(swatch.default[1], colorRampPalette(RColorBrewer::brewer.pal(12, "Paired"))(ncol(x1))))
ggplot(melt(cbind.data.frame(n=1:nrow(x1), x1), id="n"), aes(x=n, y=value, colour=variable)) + geom_boxplot(fill="#FFFFFF", size=0.66, position=position_dodge(1.1*nrow(x1)))
set_swatch(swatch.default)
# Please ENTER the selected independent variables for which to draw box plots.
# Please use numbers, not column names. E.g., c(1:5, 7, 8) uses columns 1,2,3,4,5,7,8.
boxplots_independent_variables = c(7:12) # use only the PAY_ variables
DVvalues = unique(estimation_data[,dependent_variable])
x0 = estimation_data[which(estimation_data[,dependent_variable]==DVvalues[1]),boxplots_independent_variables]
x1 = estimation_data[which(estimation_data[,dependent_variable]==DVvalues[2]),boxplots_independent_variables]
colnames(x0) <- 1:ncol(x0)
colnames(x1) <- 1:ncol(x1)
swatch.default <- as.character(swatch())
set_swatch(c(swatch.default[1], colorRampPalette(RColorBrewer::brewer.pal(12, "Paired"))(ncol(x1))))
ggplot(melt(cbind.data.frame(n=1:nrow(x1), x1), id="n"), aes(x=n, y=value, colour=variable)) + geom_boxplot(fill="#FFFFFF", size=0.66, position=position_dodge(1.1*nrow(x1)))
set_swatch(swatch.default)
# We first turn the data into data.frame's
estimation_data = data.frame(estimation_data)
validation_data = data.frame(validation_data)
test_data = data.frame(test_data)
formula_log=paste(colnames(estimation_data[,dependent_variable,drop=F]),paste(Reduce(paste,sapply(head(independent_variables,-1), function(i) paste(colnames(estimation_data)[i],"+",sep=""))),colnames(estimation_data)[tail(independent_variables,1)],sep=""),sep="~") # When drop is FALSE, the dimensions of the object are kept. head(x,-1) returns all but the last element of x.
logreg_solution <- glm(formula_log, family=binomial(link="logit"),  data=estimation_data)
log_coefficients <- round(summary(logreg_solution)$coefficients,1)
knitr::kable(round(log_coefficients,2))
swatch.default <- as.character(swatch())
set_swatch(c(swatch.default[1], colorRampPalette(RColorBrewer::brewer.pal(12, "Paired"))(ncol(x0))))
ggplot(melt(cbind.data.frame(n=1:nrow(x0), x0), id="n"), aes(x=n, y=value, colour=variable)) + geom_boxplot(fill="#FFFFFF", size=0.66, position=position_dodge(1.1*nrow(x0)))
set_swatch(swatch.default)
# We first turn the data into data.frame's
estimation_data = data.frame(estimation_data)
validation_data = data.frame(validation_data)
test_data = data.frame(test_data)
formula_log=paste(colnames(estimation_data[,dependent_variable,drop=F]),paste(Reduce(paste,sapply(head(independent_variables,-1), function(i) paste(colnames(estimation_data)[i],"+",sep=""))),colnames(estimation_data)[tail(independent_variables,1)],sep=""),sep="~") # When drop is FALSE, the dimensions of the object are kept. head(x,-1) returns all but the last element of x.
logreg_solution <- glm(formula_log, family=binomial(link="logit"),  data=estimation_data)
log_coefficients <- round(summary(logreg_solution)$coefficients,1)
knitr::kable(round(log_coefficients,2))
# Let's get the probabilities for the 3 types of data from the logistic regression
estimation_Probability_class1_log<-predict(logreg_solution, type="response", newdata=estimation_data[,independent_variables])
validation_Probability_class1_log<-predict(logreg_solution, type="response", newdata=validation_data[,independent_variables])
test_Probability_class1_log<-predict(logreg_solution, type="response", newdata=test_data[,independent_variables])
# Let's get the decision of the logistic regression for the 3 types of data
estimation_prediction_class_log=1*as.vector(estimation_Probability_class1_log > Probability_Threshold)
validation_prediction_class_log=1*as.vector(validation_Probability_class1_log > Probability_Threshold)
test_prediction_class_log=1*as.vector(test_Probability_class1_log > Probability_Threshold)
Classification_Table=rbind(validation_data[,dependent_variable],validation_prediction_class_log,validation_Probability_class1_log)
rownames(Classification_Table)<-c("Actual Class","Predicted Class","Probability of Class 1")
colnames(Classification_Table)<- paste("Obs", 1:ncol(Classification_Table), sep=" ")
knitr::kable(head(t(round(Classification_Table,2)), max_data_report)) #t(x) returns the transpose of x
# Name the variables numerically so that they look ok on the tree plots
independent_variables_nolabel = paste("IV", 1:length(independent_variables), sep="")
estimation_data_nolabel = cbind(estimation_data[,dependent_variable], estimation_data[,independent_variables])
colnames(estimation_data_nolabel)<- c(colnames(estimation_data)[dependent_variable],independent_variables_nolabel)
validation_data_nolabel = cbind(validation_data[,dependent_variable], validation_data[,independent_variables])
colnames(validation_data_nolabel)<- c(dependent_variable,independent_variables_nolabel)
test_data_nolabel = cbind(test_data[,dependent_variable], test_data[,independent_variables])
colnames(test_data_nolabel)<- c(dependent_variable,independent_variables_nolabel)
estimation_data_nolabel = data.frame(estimation_data_nolabel)
validation_data_nolabel = data.frame(validation_data_nolabel)
test_data_nolabel = data.frame(test_data_nolabel)
formula=paste(colnames(estimation_data)[dependent_variable],paste(Reduce(paste,sapply(head(independent_variables_nolabel,-1), function(i) paste(i,"+",sep=""))),tail(independent_variables_nolabel,1),sep=""),sep="~")
CART_tree<-rpart(formula, data= estimation_data_nolabel,method="class", control=CART_control)
rpart.plot(CART_tree, box.palette="OrBu", type=3, extra=1, fallen.leaves=F, branch.lty=3)
# Tree parameter
# Please ENTER the new tree (CART) complexity control cp
CART_cp = 0.00068
CART_tree_large<-rpart(formula, data= estimation_data_nolabel,method="class", control=rpart.control(cp = CART_cp))
rpart.plot(CART_tree_large, box.palette="OrBu", type=3, extra=1, fallen.leaves=F, branch.lty=3)
make_pdf_file = 0 # Haga este número 1 si quiere un archivo PDF, 0 para HTML
source("../../AnalyticsLibraries/library.R")
source("../../AnalyticsLibraries/heatmapOutput.R")
# Opciones de paquetes
ggthemr('fresh')  # tema de ggplot
opts_knit$set(progress=FALSE, verbose=FALSE)
opts_chunk$set(echo=FALSE, fig.align="center", fig.width=10, fig.height=6.2)
options(knitr.kable.NA = '')
# Por favor INGRESE el nombre del archivo
datafile_name = "../../Data/UCI_Credit_Card.csv"
ProjectData <- read.csv(datafile_name)
# Convertimos los datos a la clase data.matrix para que sea mas fácil de manipular
ProjectData <- data.matrix(ProjectData)
# Por favor INGRESE la variable dependiente(clase).
# Por favor use números, no nombres de columnas. Por ejemplo, 82 usa la columna en la posición 82 como la variable dependiente.
# Necesita asegurarse que la variable dependiente solo tome dos valores: 0 y 1.
dependent_variable = 25
# Por favor ingrese los atributos a usar como variables independientes.
# Por favor use números, no nombres de columnas. Por ejemplo, c(1:5, 7, 8) usa las columnas 1,2,3,4,5,7,8.
independent_variables = c(1:24) # usa todos los atributos disponibles
dependent_variable = unique(sapply(dependent_variable,function(i) min(ncol(ProjectData), max(i,1))))
independent_variables = unique(sapply(independent_variables,function(i) min(ncol(ProjectData), max(i,1))))
if (length(unique(ProjectData[,dependent_variable])) !=2){
cat("\n*****\n REVISE DE NUEVO, LA VARIABLE DEPENDIENTE TOMA MÁS DE 2 VALORES")
cat("\nDividiendo los datos respecto a la mediana...\n*****\n ")
new_dependent = ProjectData[,dependent_variable] >= median(ProjectData[,dependent_variable])
ProjectData[,dependent_variable] <- 1*new_dependent
}
# Por favor INGRESE el umbral de probabilidad arriba del cual una observación será categorizada como clase 1:
Probability_Threshold = 0.5 # entre 0 y 1
# Por favor INGRESE el porcentaje de datos usados para la estimación
estimation_data_percent = 80
validation_data_percent = 10
test_data_percent = 100-estimation_data_percent-validation_data_percent
# Por favor INGRESE 1 si quiere dividir los datos aleatoriamente en los conjuntos de estimación y validación/evaluación
random_sampling = 0
# Parámetros del árbol
# Por favor INGRESE el control de complejidad cp del árbol(CART), por ejemplo de 0.0001 a 0.02, dependiendo de los datos.
CART_cp = 0.0025
CART_control = rpart.control(cp = CART_cp)
# Por favor INGRESE el significado de las clases 1 y 0:
class_1_interpretation = "default"
class_0_interpretation = "no default"
# Por favor INGRESE los valores de ganancia/costo de clasificar correcta o incorrectamente los datos:
actual_1_predict_1 = 0
actual_1_predict_0 = -100000
actual_0_predict_1 = 0
actual_0_predict_0 = 20000
Profit_Matrix = matrix(c(actual_1_predict_1, actual_0_predict_1, actual_1_predict_0, actual_0_predict_0), ncol=2)
colnames(Profit_Matrix) <- c(paste("Predict 1 (", class_1_interpretation, ")", sep = ""), paste("Predict 0 (", class_0_interpretation, ")", sep = ""))
rownames(Profit_Matrix) <- c(paste("Actual 1 (", class_1_interpretation, ")", sep = ""), paste("Actual 0 (", class_0_interpretation, ")", sep = ""))
# Por favor INGRESE el máximo número de observaciones a mostrar en el reporte y diapositivas
# (El número predefinido es 50. Si el número es demasiado grande el reporte y las diapositivas podrían no ser generados -  muy lento o no funcionará!!)
max_data_report = 10
# let's make the data into data.matrix classes so that we can easier visualize them
ProjectData = data.matrix(ProjectData)
# let's make the data into data.matrix classes so that we can easier visualize them
ProjectData = data.matrix(ProjectData)
21 "Q16_21_Offers boats that are easy to maintain and or repair"
22 "Q16_22_Offers boats that are easy to use"
23 "Q16_23_Offers boats that are easy to clean up"
`r min(max_data_report, nrow(ProjectData))`
rmarkdown::render()
getwd()
rmarkdown::render("Analisis_Clasificacion_Interactivo.Rmd")
knit_with_parameters('~/R/UCAanalytics/Sesiones/Sesiones_5_6_Clasificacion/Analisis_Clasificacion_Interactivo.Rmd')
rmarkdown::render("Analisis_Clasificacion_Interactivo.Rmd")
print(getwd())
# A list of R libraries often used
if (require(devtools)==FALSE){install.packages("devtools"); library(devtools)}
if (require(slidifyLibraries)==FALSE){install_github("slidifyLibraries", "ramnathv"); library(slidifyLibraries)}
if (require(slidify)==FALSE){install_github("slidify", "ramnathv")}; library(slidify)
if (require(shiny)==FALSE){install.packages("shiny")}; library(shiny)
if (require(knitr)==FALSE){install.packages("knitr")}; library(knitr)
if (require(ggplot2)==FALSE){install.packages("ggplot2")}; library(ggplot2)
if (require(png)==FALSE){install.packages("png")}; library(png)
if (require(grid)==FALSE){install.packages("xtable")}; library(grid)
if (require(xtable)==FALSE){install.packages("xtable")}; library(xtable)
if (require(colorspace)==FALSE){install.packages("colorspace")}; library(colorspace)
if (require(Hmisc)==FALSE){install.packages("Hmisc")}; library(Hmisc)
if (require(vegan)==FALSE){install.packages("vegan")}; library(vegan)
if (require(fpc)==FALSE){install.packages("fpc")}; library(fpc)
if (require(GPArotation)==FALSE){install.packages("GPArotation")}; library(GPArotation)
if (require(cluster)==FALSE){install.packages("cluster")}; library(cluster)
if (require(FactoMineR)==FALSE){install.packages("FactoMineR")}; library(FactoMineR)
if (require(psych)==FALSE){install.packages("psych")}; library(psych)
if (require(class)==FALSE){install.packages("class")}; library(class)
if (require(e1071)==FALSE){install.packages("e1071")}; library(e1071)
if (require(lars)==FALSE){install.packages("lars")}; library(lars)
if (require(zoo)==FALSE){install.packages("zoo")}; library(zoo)
if (require(datasets)==FALSE){install.packages("datasets")}; library(datasets)
if (require(tikzDevice)==FALSE){install.packages("tikzDevice")}; library(tikzDevice)
if (require(animation)==FALSE){install.packages("animation")}; library(animation)
if (require(evaluate)==FALSE){install.packages("evaluate")}; library(evaluate)
if (require(highlight)==FALSE){install.packages("highlight")}; library(highlight)
if (require(Cairo)==FALSE){install.packages("Cairo")}; library(Cairo)
if (require(cairoDevice)==FALSE){install.packages("cairoDevice")}; library(cairoDevice)
# A list of R libraries often used
if (require(devtools)==FALSE){install.packages("devtools"); library(devtools)}
if (require(slidifyLibraries)==FALSE){install_github("slidifyLibraries", "ramnathv"); library(slidifyLibraries)}
if (require(slidify)==FALSE){install_github("slidify", "ramnathv")}; library(slidify)
if (require(shiny)==FALSE){install.packages("shiny")}; library(shiny)
if (require(knitr)==FALSE){install.packages("knitr")}; library(knitr)
if (require(ggplot2)==FALSE){install.packages("ggplot2")}; library(ggplot2)
if (require(png)==FALSE){install.packages("png")}; library(png)
if (require(grid)==FALSE){install.packages("xtable")}; library(grid)
if (require(xtable)==FALSE){install.packages("xtable")}; library(xtable)
if (require(colorspace)==FALSE){install.packages("colorspace")}; library(colorspace)
if (require(Hmisc)==FALSE){install.packages("Hmisc")}; library(Hmisc)
if (require(vegan)==FALSE){install.packages("vegan")}; library(vegan)
if (require(fpc)==FALSE){install.packages("fpc")}; library(fpc)
if (require(GPArotation)==FALSE){install.packages("GPArotation")}; library(GPArotation)
if (require(cluster)==FALSE){install.packages("cluster")}; library(cluster)
if (require(FactoMineR)==FALSE){install.packages("FactoMineR")}; library(FactoMineR)
if (require(psych)==FALSE){install.packages("psych")}; library(psych)
if (require(class)==FALSE){install.packages("class")}; library(class)
if (require(e1071)==FALSE){install.packages("e1071")}; library(e1071)
if (require(lars)==FALSE){install.packages("lars")}; library(lars)
if (require(zoo)==FALSE){install.packages("zoo")}; library(zoo)
if (require(datasets)==FALSE){install.packages("datasets")}; library(datasets)
if (require(tikzDevice)==FALSE){install.packages("tikzDevice")}; library(tikzDevice)
if (require(animation)==FALSE){install.packages("animation")}; library(animation)
if (require(evaluate)==FALSE){install.packages("evaluate")}; library(evaluate)
if (require(highlight)==FALSE){install.packages("highlight")}; library(highlight)
if (require(Cairo)==FALSE){install.packages("Cairo")}; library(Cairo)
if (require(cairoDevice)==FALSE){install.packages("cairoDevice")}; library(cairoDevice)
# installs all necessary libraries from CRAN or Github
get_libraries <- function(filenames_list) suppressPackageStartupMessages({
lapply(filenames_list, function(thelibrary){
thelibrary.split <- strsplit(thelibrary, "/")[[1]]
if (length(thelibrary.split) > 1) {
# install from Github
if (!suppressWarnings(require(thelibrary.split[2], character.only=TRUE))) {
devtools::install_github(thelibrary, quiet=TRUE)
library(thelibrary.split[2], character.only=TRUE)
}
} else {
# install from CRAN
if (!suppressWarnings(require(thelibrary, character.only=TRUE))) {
install.packages(thelibrary, repos="http://cran.r-project.org/", quiet=TRUE)
library(thelibrary, character.only=TRUE)
}
}
})
})
get_libraries
get_libraries(libraries_used)
libraries_used=c("devtools","knitr","graphics","grDevices","xtable","pryr",
"Hmisc","vegan","fpc","GPArotation","FactoMineR","cluster",
"psych","stringr","googleVis", "png","ggplot2","googleVis",
"gridExtra", "reshape2", "DT",
"shiny",
"ramnathv/slidify", "cttobin/ggthemr", "dplyr",
"vkapartzianis/formattable", "ggdendro","ROCR",
"networkD3","rpart.plot","mrjoh3/c3","glmnet",
"hong-revo/glmnetUtils","randomForest","xgboost")
get_libraries(libraries_used)
my_summary <- function(thedata){
res = apply(thedata, 2, function(r) c(min(r), quantile(r, 0.25), quantile(r, 0.5), mean(r), quantile(r, 0.75), max(r), sd(r)))
res <- round(res,2)
colnames(res) <- colnames(thedata)
rownames(res) <- c("min", "25 percent", "median", "mean", "75 percent", "max", "std")
t(res)
}
# Determine document output format, return "html" by default
getDocumentOutputFormat <- function() {
format <- opts_knit$get('rmarkdown.pandoc.to')
if (!is.null(format)) format else "html"
}
# Format tables for html/latex output
normalize.abs <- function(x, min=0, max=1, na.rm=FALSE) normalize(abs(x), min, max, na.rm)
iprint.df <- function(df, scale=FALSE) {
if (getDocumentOutputFormat() == "html") {
if (class(df) != "data.frame")
df <- as.data.frame(df)
x <- lapply(colnames(df), function(col) {
if (is.numeric(df[, col]))
color_bar(rgb(238, 238, 238, max=255), normalize.abs, min=0.1, na.rm=TRUE)
else
formatter("span")
})
names(x) <- colnames(df)
shiny::tags$div(class="formattable_container", shiny::HTML(gsub("NA", "", format_table(df, x))))
} else if (opts_knit$get('rmarkdown.pandoc.to') == "latex") {
cat(ifelse(scale, "\\setkeys{Gin}{height=\\textheight}\\adjustbox{width=\\linewidth}{", "\\begin{center}"))
cat(kable(df, format="latex", booktabs=TRUE, longtable=!scale))
cat(ifelse(scale, "}\\setkeys{Gin}{height=\\maxheight}", "\\end{center}"))
} else {
kable(df)
}
}
gvisTable()
rmarkdown::render("Analisis_Clasificacion_Interactivo.Rmd")
rmarkdown::render("Analisis_Clasificacion_Interactivo.Rmd")
if(1)
1
if(1)
1
if(0)
if(0):
if(0) 2
if(0)
3
if(0) {2}
if(0) {print(2)}
if(1) {print(2)}
if(0.00001) {print(2)}
if(0.00001) {print(2)} else {print(3)}
if(0) {print(2)} else {print(3)}
max_data_report<- 10
local_directory = "."
source(paste(local_directory,"../../AnalyticsLibraries/library.R", sep="/"))
source(paste(local_directory,"../../AnalyticsLibraries/heatmapOutput.R", sep = "/"))
cluster_file_ini = "Boats_cluster" # make sure this file exists in the "data" directory
datafile_name = "Boats"
ProjectData <- read.csv(
paste(paste(local_directory, "data", sep="/"),
paste(datafile_name,"csv", sep="."), sep = "/"))
# is predicted as class 1:
Probability_Threshold=50 # between 1 and 99%
# Please ENTER the percentage of data used for estimation
estimation_data_percent = 80
validation_data_percent = 10
# Please enter 0 if you want to "randomly" split the data in estimation and validation/test
random_sampling = 0
# this contains only the matrix ProjectData
